import * as http from 'http';
import { Logger } from './logger';
import { AiCacheManager } from './aiCache';

// Define the structure for the AI analysis result
export interface AIAnalysis {
    summary: string;
    // Potentially add more fields later, e.g., semantic_highlights: any[];
}

const AI_SERVICE_HOST = '127.0.0.1'; // Use 127.0.0.1 instead of localhost for clarity
const AI_SERVICE_PORT = 5111;
const AI_SERVICE_PATH = '/analyze_diff';

// å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
let cacheManager: AiCacheManager | null = null;

/**
 * åˆå§‹åŒ–AIç¼“å­˜ç®¡ç†å™¨
 * @param cacheDir ç¼“å­˜ç›®å½•
 * @param config ç¼“å­˜é…ç½®
 * @param logger æ—¥å¿—è®°å½•å™¨
 */
export function initializeAICache(cacheDir: string, config: any, logger?: Logger): void {
	if (config.enabled) {
		cacheManager = new AiCacheManager(cacheDir, {
			maxMemoryItems: config.maxMemoryItems,
			maxDiskItems: config.maxDiskItems,
			ttlHours: config.ttlHours,
			enabled: config.enabled
		}, logger);
		logger?.log('[AI Service] Cache manager initialized');
	} else {
		cacheManager = null;
		logger?.log('[AI Service] Cache disabled');
	}
}

/**
 * è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
 */
export function getCacheStats(): any {
	return cacheManager?.getStats() || {
		memoryItems: 0,
		diskItems: 0,
		totalSize: '0 Bytes',
		hitRate: 'N/A'
	};
}

/**
 * æ¸…é™¤æ‰€æœ‰ç¼“å­˜
 */
export async function clearCache(): Promise<void> {
	if (cacheManager) {
		await cacheManager.clear();
	}
}

/**
 * Calls the Python AI service to analyze a file diff.
 * @param filePath The path of the file being diffed.
 * @param fileDiff The raw diff content.
 * @param contentBefore Content before changes (optional, might be useful for AI).
 * @param contentAfter Content after changes (optional, might be useful for AI).
 * @param logger Optional logger instance.
 * @returns A Promise resolving to the AIAnalysis object or null if analysis fails.
 */
export function analyzeDiff(
	filePath: string,
	fileDiff: string,
	contentBefore: string | null,
	contentAfter: string | null,
	logger?: Logger
): Promise<AIAnalysis | null> {
	return new Promise(async (resolve) => {
		// æ•°æ®æµè°ƒè¯•ï¼šè®°å½•AIæœåŠ¡è¯·æ±‚å¼€å§‹
		logger?.log('[AI Service] ğŸš€ Starting AI analysis request');
		logger?.log(`[AI Service] ğŸ“Š Request data - FilePath: ${filePath}, DiffLength: ${fileDiff?.length || 0} chars`);
		logger?.log(`[AI Service] ğŸ“ Content info - Before: ${contentBefore?.length || 0} chars, After: ${contentAfter?.length || 0} chars`);

		// æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
		if (!fileDiff || fileDiff.trim() === '') {
			logger?.log(`[AI Service] âš ï¸ Skipping empty diff for: ${filePath}`);
			resolve(null);
			return;
		}

		// æ•°æ®æµè°ƒè¯•ï¼šè®°å½•ç¼“å­˜æ£€æŸ¥
		logger?.log('[AI Service] ğŸ” Checking cache for analysis result');

		// å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
		if (cacheManager) {
			const cacheKey = cacheManager.generateCacheKey(fileDiff, filePath);
			logger?.log(`[AI Service] ğŸ”‘ Generated cache key: ${cacheKey.substring(0, 16)}...`);

			const cacheCheckStartTime = Date.now();
			const cachedResult = await cacheManager.get(cacheKey);
			const cacheCheckEndTime = Date.now();

			if (cachedResult) {
				logger?.log(`[AI Service] âœ… Cache hit for: ${filePath} (checked in ${cacheCheckEndTime - cacheCheckStartTime}ms)`);
				logger?.log(`[AI Service] ğŸ“‹ Cached result - Summary length: ${cachedResult.summary?.length || 0} chars`);
				resolve(cachedResult);
				return;
			} else {
				logger?.log(`[AI Service] âŒ Cache miss for: ${filePath} (checked in ${cacheCheckEndTime - cacheCheckStartTime}ms)`);
			}
		} else {
			logger?.log('[AI Service] âš ï¸ Cache manager not available - proceeding without cache');
		}

		// æ•°æ®æµè°ƒè¯•ï¼šè®°å½•HTTPè¯·æ±‚æ„å»º
		const postData = JSON.stringify({
			file_path: filePath,
			file_diff: fileDiff,
			content_before: contentBefore,
			content_after: contentAfter
		});

		logger?.log(`[AI Service] ğŸ“¦ Built HTTP request - PayloadSize: ${postData.length} chars`);
		logger?.log(`[AI Service] ğŸŒ Target endpoint: ${AI_SERVICE_HOST}:${AI_SERVICE_PORT}${AI_SERVICE_PATH}`);

		const options: http.RequestOptions = {
			hostname: AI_SERVICE_HOST,
			port: AI_SERVICE_PORT,
			path: AI_SERVICE_PATH,
			method: 'POST',
			headers: {
				'Content-Type': 'application/json',
				'Content-Length': Buffer.byteLength(postData)
			},
			timeout: 30000
		};

		logger?.log(`[AI Service] ğŸš€ Sending HTTP request to AI service for: ${filePath}`);
		const requestStartTime = Date.now();

		const req = http.request(options, (res) => {
			let responseBody = '';
			res.setEncoding('utf8');

			// æ•°æ®æµè°ƒè¯•ï¼šè®°å½•å“åº”æ¥æ”¶
			logger?.log(`[AI Service] ğŸ“¡ Receiving response - StatusCode: ${res.statusCode}, Headers: ${JSON.stringify(res.headers)}`);

			res.on('data', (chunk) => {
				responseBody += chunk;
				logger?.log(`[AI Service] ğŸ“Š Received data chunk - Size: ${chunk.length} chars, Total so far: ${responseBody.length} chars`);
			});

			res.on('end', async () => {
				const requestEndTime = Date.now();
				const responseTime = requestEndTime - requestStartTime;

				logger?.log(`[AI Service] â±ï¸ Request completed in ${responseTime}ms - StatusCode: ${res.statusCode}, ResponseSize: ${responseBody.length} chars`);

				if (res.statusCode === 200) {
					try {
						// æ•°æ®æµè°ƒè¯•ï¼šè®°å½•å“åº”è§£æ
						logger?.log(`[AI Service] ğŸ”„ Parsing JSON response for ${filePath}`);
						const parseStartTime = Date.now();
						const parsedData = JSON.parse(responseBody);
						const parseEndTime = Date.now();

						logger?.log(`[AI Service] â±ï¸ JSON parsing completed in ${parseEndTime - parseStartTime}ms`);
						logger?.log(`[AI Service] ğŸ“‹ Parsed response structure: ${JSON.stringify(Object.keys(parsedData))}`);

						if (parsedData && parsedData.analysis && parsedData.analysis.summary) {
							const analysis = parsedData.analysis as AIAnalysis;
							logger?.log(`[AI Service] âœ… Valid analysis received for: ${filePath}`);
							logger?.log(`[AI Service] ğŸ“ Analysis summary preview: "${analysis.summary.substring(0, 100)}..."`);

							// æ•°æ®æµè°ƒè¯•ï¼šè®°å½•ç¼“å­˜å­˜å‚¨
							if (cacheManager) {
								logger?.log(`[AI Service] ğŸ’¾ Storing result in cache for: ${filePath}`);
								const cacheStoreStartTime = Date.now();
								const cacheKey = cacheManager.generateCacheKey(fileDiff, filePath);
								await cacheManager.set(cacheKey, analysis);
								const cacheStoreEndTime = Date.now();
								logger?.log(`[AI Service] âœ… Cached result for: ${filePath} (stored in ${cacheStoreEndTime - cacheStoreStartTime}ms)`);
							}

							resolve(analysis);
						} else {
							logger?.logError(`[AI Service] âŒ Invalid response format from AI service for ${filePath}: ${responseBody}`);
							logger?.logError(`[AI Service] ğŸ” Expected structure: {analysis: {summary: string}}, Got: ${JSON.stringify(parsedData)}`);
							resolve(null);
						}
					} catch (e: any) {
						logger?.logError(`[AI Service] âŒ Error parsing JSON response for ${filePath}: ${e} - Response: ${responseBody}`);
						logger?.logError(`[AI Service] ğŸ” Parse error details: ${e instanceof Error ? e.stack : 'Unknown parse error'}`);
						resolve(null);
					}
				} else {
					logger?.logError(`[AI Service] âŒ Request failed for ${filePath} - Status Code: ${res.statusCode} - Response: ${responseBody}`);
					logger?.logError(`[AI Service] ğŸ” Response headers: ${JSON.stringify(res.headers)}`);
					resolve(null);
				}
			});
		});

		req.on('error', (e: Error) => {
			const requestEndTime = Date.now();
			const failedRequestTime = requestEndTime - requestStartTime;

			logger?.logError(`[AI Service] âŒ Request error for ${filePath} after ${failedRequestTime}ms: ${e.message}`);
			logger?.logError(`[AI Service] ğŸ” Error details: ${e.stack || 'No stack trace'}`);

			if (e.message.includes('ECONNREFUSED')) {
				logger?.logError('[AI Service] ğŸ”Œ Connection refused. Is the Python AI server running on port 5111?');
			} else if (e.message.includes('ETIMEDOUT')) {
				logger?.logError('[AI Service] â° Connection timed out. Check network connectivity to AI service.');
			}
			resolve(null);
		});

		req.on('timeout', () => {
			const requestEndTime = Date.now();
			const timeoutDuration = requestEndTime - requestStartTime;

			logger?.logError(`[AI Service] â° Request timed out for ${filePath} after ${timeoutDuration}ms.`);
			req.destroy(new Error('Request timed out'));
			resolve(null);
		});

		// æ•°æ®æµè°ƒè¯•ï¼šè®°å½•æ•°æ®å‘é€
		logger?.log(`[AI Service] ğŸ“¤ Writing request data - Size: ${postData.length} chars`);
		// Write data to request body
		req.write(postData);
		req.end();
		logger?.log(`[AI Service] âœ… Request sent successfully for: ${filePath}`);
	});
}

/**
 * æ‰¹é‡åˆ†æå¤šä¸ªæ–‡ä»¶çš„å·®å¼‚
 * @param analyses Array of file analysis requests
 * @param logger Logger instance
 * @returns Promise resolving to array of analysis results
 */
export async function analyzeDiffBatch(
	analyses: Array<{
		filePath: string;
		fileDiff: string;
		contentBefore: string | null;
		contentAfter: string | null;
	}>,
	logger?: Logger
): Promise<Array<{ filePath: string; analysis: AIAnalysis | null }>> {
	// é™åˆ¶å¹¶å‘æ•°é‡ä»¥é¿å…è¿‡è½½AIæœåŠ¡
	const BATCH_SIZE = 3;
	const results: Array<{ filePath: string; analysis: AIAnalysis | null }> = [];

	for (let i = 0; i < analyses.length; i += BATCH_SIZE) {
		const batch = analyses.slice(i, i + BATCH_SIZE);
		const batchPromises = batch.map(async (item) => {
			const analysis = await analyzeDiff(item.filePath, item.fileDiff, item.contentBefore, item.contentAfter, logger);
			return { filePath: item.filePath, analysis };
		});

		const batchResults = await Promise.all(batchPromises);
		results.push(...batchResults);

		// åœ¨æ‰¹æ¬¡ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿä»¥é¿å…è¿‡è½½
		if (i + BATCH_SIZE < analyses.length) {
			await new Promise(resolve => setTimeout(resolve, 100));
		}
	}

	return results;
}

/**
 * æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨
 * @param logger Logger instance
 * @returns Promise resolving to boolean indicating service availability
 */
export function checkAIServiceAvailability(logger?: Logger): Promise<boolean> {
	return new Promise((resolve) => {
		const options: http.RequestOptions = {
			hostname: AI_SERVICE_HOST,
			port: AI_SERVICE_PORT,
			path: '/health', // å‡è®¾AIæœåŠ¡æœ‰å¥åº·æ£€æŸ¥ç«¯ç‚¹
			method: 'GET',
			timeout: 3000
		};

		const req = http.request(options, (res) => {
			resolve(res.statusCode === 200);
		});

		req.on('error', () => {
			logger?.log('[AI Service] Service not available');
			resolve(false);
		});

		req.on('timeout', () => {
			req.destroy();
			resolve(false);
		});

		req.end();
	});
}

/**
 * Analyze file history using the dedicated endpoint
 * @param filePath The path of the file
 * @param prompt The analysis prompt
 * @param logger Optional logger instance
 * @returns A Promise resolving to the AIAnalysis object or null if analysis fails
 */
export function analyzeFileHistory(
	filePath: string,
	prompt: string,
	logger?: Logger
): Promise<AIAnalysis | null> {
	return new Promise(async (resolve) => {
		// æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
		if (!prompt || prompt.trim() === '') {
			logger?.log(`[AI Service] Skipping empty prompt for file history: ${filePath}`);
			resolve(null);
			return;
		}

		// å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
		if (cacheManager) {
			const cacheKey = cacheManager.generateCacheKey(prompt, `file_history:${filePath}`);
			const cachedResult = await cacheManager.get(cacheKey);
			if (cachedResult) {
				logger?.log(`[AI Service] Cache hit for file history: ${filePath}`);
				resolve(cachedResult);
				return;
			}
		}

		const postData = JSON.stringify({
			file_path: filePath,
			file_diff: prompt // å¤ç”¨è¿™ä¸ªå­—æ®µä¼ é€’å®Œæ•´çš„æç¤ºè¯
		});

		const options: http.RequestOptions = {
			hostname: AI_SERVICE_HOST,
			port: AI_SERVICE_PORT,
			path: '/analyze_file_history', // ä½¿ç”¨ä¸“é—¨çš„æ–‡ä»¶å†å²åˆ†æç«¯ç‚¹
			method: 'POST',
			headers: {
				'Content-Type': 'application/json',
				'Content-Length': Buffer.byteLength(postData)
			},
			timeout: 15000 // æ–‡ä»¶å†å²åˆ†æå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
		};

		logger?.log(`[AI Service] Sending file history analysis request for: ${filePath}`);

		const req = http.request(options, (res) => {
			let responseBody = '';
			res.setEncoding('utf8');

			res.on('data', (chunk) => {
				responseBody += chunk;
			});

			res.on('end', async () => {
				if (res.statusCode === 200) {
					try {
						const parsedData = JSON.parse(responseBody);
						if (parsedData && parsedData.analysis && parsedData.analysis.summary) {
							const analysis = parsedData.analysis as AIAnalysis;
							logger?.log(`[AI Service] Received file history analysis for: ${filePath}`);

							// ç¼“å­˜ç»“æœ
							if (cacheManager) {
								const cacheKey = cacheManager.generateCacheKey(prompt, `file_history:${filePath}`);
								await cacheManager.set(cacheKey, analysis);
								logger?.log(`[AI Service] Cached file history result for: ${filePath}`);
							}

							resolve(analysis);
						} else {
							logger?.logError(`[AI Service] Invalid response format from file history service for ${filePath}: ${responseBody}`);
							resolve(null);
						}
					} catch (e: any) {
						logger?.logError(`[AI Service] Error parsing JSON response for file history ${filePath}: ${e} - Response: ${responseBody}`);
						resolve(null);
					}
				} else {
					logger?.logError(`[AI Service] File history request failed for ${filePath} - Status Code: ${res.statusCode} - Response: ${responseBody}`);
					resolve(null);
				}
			});
		});

		req.on('error', (e: Error) => {
			logger?.logError(`[AI Service] File history request error for ${filePath}: ${e.message}`);
			if (e.message.includes('ECONNREFUSED')) {
				logger?.logError('[AI Service] Connection refused. Is the Python AI server running on port 5111?');
			}
			resolve(null);
		});

		req.on('timeout', () => {
			logger?.logError(`[AI Service] File history request timed out for ${filePath}.`);
			req.destroy(new Error('Request timed out'));
			resolve(null);
		});

		// Write data to request body
		req.write(postData);
		req.end();
	});
}

/**
 * Analyze file version comparison using the dedicated endpoint
 * @param filePath The path of the file
 * @param prompt The analysis prompt
 * @param logger Optional logger instance
 * @returns A Promise resolving to the AIAnalysis object or null if analysis fails
 */
export function analyzeFileVersionComparison(
	filePath: string,
	prompt: string,
	logger?: Logger
): Promise<AIAnalysis | null> {
	return new Promise(async (resolve) => {
		// æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
		if (!prompt || prompt.trim() === '') {
			logger?.log(`[AI Service] Skipping empty prompt for file version comparison: ${filePath}`);
			resolve(null);
			return;
		}

		// å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
		if (cacheManager) {
			const cacheKey = cacheManager.generateCacheKey(prompt, `file_version_comparison:${filePath}`);
			const cachedResult = await cacheManager.get(cacheKey);
			if (cachedResult) {
				logger?.log(`[AI Service] Cache hit for file version comparison: ${filePath}`);
				resolve(cachedResult);
				return;
			}
		}

		const postData = JSON.stringify({
			file_path: filePath,
			file_diff: prompt // å¤ç”¨è¿™ä¸ªå­—æ®µä¼ é€’å®Œæ•´çš„æç¤ºè¯
		});

		const options: http.RequestOptions = {
			hostname: AI_SERVICE_HOST,
			port: AI_SERVICE_PORT,
			path: '/analyze_file_version_comparison', // ä½¿ç”¨ä¸“é—¨çš„æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æç«¯ç‚¹
			method: 'POST',
			headers: {
				'Content-Type': 'application/json',
				'Content-Length': Buffer.byteLength(postData)
			},
			timeout: 15000 // æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
		};

		logger?.log(`[AI Service] Sending file version comparison analysis request for: ${filePath}`);

		const req = http.request(options, (res) => {
			let data = '';

			res.on('data', (chunk) => {
				data += chunk;
			});

			res.on('end', async () => {
				try {
					const response = JSON.parse(data);
					if (response.analysis && response.analysis.summary) {
						const aiAnalysis: AIAnalysis = {
							summary: response.analysis.summary
						};

						// ç¼“å­˜ç»“æœ
						if (cacheManager) {
							const cacheKey = cacheManager.generateCacheKey(prompt, `file_version_comparison:${filePath}`);
							await cacheManager.set(cacheKey, aiAnalysis);
						}

						logger?.log(`[AI Service] File version comparison analysis completed for: ${filePath}`);
						resolve(aiAnalysis);
					} else {
						logger?.logError(`[AI Service] Invalid response format for file version comparison analysis: ${filePath}`);
						resolve(null);
					}
				} catch (error) {
					logger?.logError(`[AI Service] Failed to parse file version comparison analysis response for ${filePath}: ${error}`);
					resolve(null);
				}
			});
		});

		req.on('error', (error) => {
			logger?.logError(`[AI Service] Request error for file version comparison analysis ${filePath}: ${error}`);
			resolve(null);
		});

		req.on('timeout', () => {
			logger?.logError(`[AI Service] Request timeout for file version comparison analysis: ${filePath}`);
			req.destroy();
			resolve(null);
		});

		req.write(postData);
		req.end();
	});
}
