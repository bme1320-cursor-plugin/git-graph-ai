# ai_service/server.py

import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI, OpenAIError

app = Flask(__name__)

# é…ç½®CORSä»¥å…è®¸è·¨åŸŸè®¿é—®
# CORS(app, origins=['*'])  # ç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå

# --- OpenAI Client Initialization ---
openai_client = None
api_key = os.environ.get("OPENAI_API_KEY")

if api_key:
    try:
        openai_client = OpenAI(api_key=api_key)
        print("OpenAI client initialized successfully.")
    except Exception as e:
        print(f"Error initializing OpenAI client: {e}")
else:
    print("Warning: OPENAI_API_KEY environment variable not set. AI analysis will be disabled.")
# ------------------------------------

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    if openai_client:
        return jsonify({"status": "healthy", "ai_service": "available"}), 200
    else:
        return jsonify({"status": "degraded", "ai_service": "unavailable"}), 200

@app.route('/analyze_diff', methods=['POST'])
def analyze_diff():
    """Analyzes the diff data using OpenAI API if available."""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AI analysis disabled: OPENAI_API_KEY not configured.",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»¼åˆåˆ†æè¯·æ±‚
        if 'file_path' in data and data['file_path'] in ['comprehensive_commit_analysis', 'comprehensive_comparison_analysis']:
            return handle_comprehensive_analysis(data)
        
        # åŸæœ‰çš„å•æ–‡ä»¶åˆ†æé€»è¾‘
        if 'file_diff' not in data or 'file_path' not in data:
            return jsonify({"error": "Missing or invalid data in request (requires file_path and file_diff)"}), 400
        
        file_path = data['file_path']
        file_diff = data['file_diff']
        
        # æ£€æŸ¥diffå†…å®¹æ˜¯å¦ä¸ºç©º
        if not file_diff or file_diff.strip() == '':
            return jsonify({
                "analysis": {
                    "summary": "æ–‡ä»¶æ— å®è´¨æ€§å˜æ›´ã€‚"
                }
            })

        print(f"Received request to analyze diff for: {file_path}")
        file_path = file_path.strip()
        
        # è·å–æ–‡ä»¶ç±»å‹å’Œæ‰©å±•å
        file_extension = file_path.split('.')[-1].lower() if '.' in file_path else ''
        file_name = file_path.split('/')[-1]
        
        # --- OpenAI API Call --- 
        try:
            # æ”¹è¿›çš„æç¤ºè¯ï¼Œæ›´åŠ å…·ä½“å’Œæœ‰é’ˆå¯¹æ€§
            prompt = f"""
            è¯·åˆ†æä»¥ä¸‹Gitå·®å¼‚æ–‡ä»¶çš„å˜æ›´å†…å®¹ï¼Œå¹¶æä¾›ç®€æ´çš„ä¸­æ–‡æ€»ç»“ã€‚

            æ–‡ä»¶ä¿¡æ¯ï¼š
            - æ–‡ä»¶è·¯å¾„: {file_path}
            - æ–‡ä»¶ç±»å‹: {file_extension}

            Git Diffå†…å®¹ï¼š
            ```diff
            {file_diff}
            ```

            è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼ˆä¸è¶…è¿‡80å­—ï¼‰ï¼š
            {file_name}: [æ–‡ä»¶ç®€ä»‹]ã€‚[ä¸»è¦å˜æ›´å†…å®¹]ã€‚

            è¦æ±‚ï¼š
            1. å…ˆç®€è¦è¯´æ˜æ–‡ä»¶ç”¨é€”
            2. é‡ç‚¹æè¿°å˜æ›´çš„åŠŸèƒ½æ€§å½±å“ï¼Œè€ŒéæŠ€æœ¯ç»†èŠ‚
            3. ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡è¡¨è¾¾
            4. é¿å…ä½¿ç”¨"è¿™ä¸ªæ–‡ä»¶"ç­‰æŒ‡ä»£è¯
            """

            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=100,  # å¢åŠ tokené™åˆ¶ä»¥è·å¾—æ›´è¯¦ç»†çš„åˆ†æ
                temperature=0.3,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"OpenAI Summary for {file_path}: {ai_summary}")

        except OpenAIError as e:
            print(f"OpenAI API error for {file_path}: {e}")
            ai_summary = f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}"
        except Exception as e:
            print(f"Unexpected error during OpenAI call for {file_path}: {e}")
            ai_summary = "AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        # -----------------------

        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })

    except json.JSONDecodeError:
        return jsonify({"error": "Invalid JSON format"}), 400
    except Exception as e:
        print(f"Error processing request: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def handle_comprehensive_analysis(data):
    """å¤„ç†ç»¼åˆåˆ†æè¯·æ±‚"""
    try:
        analysis_type = data['file_path']
        prompt = data.get('file_diff', '')  # åœ¨ç»¼åˆåˆ†æä¸­ï¼Œfile_diffå­—æ®µåŒ…å«å®Œæ•´çš„æç¤ºè¯
        
        if not prompt:
            return jsonify({"error": "Missing analysis prompt"}), 400
        
        print(f"Received comprehensive analysis request: {analysis_type}")
        
        # --- OpenAI API Call for Comprehensive Analysis ---
        try:
            # æ ¹æ®åˆ†æç±»å‹è°ƒæ•´ç³»ç»Ÿæç¤ºè¯
            if analysis_type == 'file_history_analysis':
                system_content = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†ææ–‡ä»¶çš„ç‰ˆæœ¬æ¼”è¿›å†å²ã€‚è¯·æä¾›ç»“æ„åŒ–çš„JSONæ ¼å¼åˆ†ææŠ¥å‘Šã€‚"
                max_tokens = 400
                temperature = 0.1
            else:
                system_content = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æGitæäº¤å’Œç‰ˆæœ¬å˜æ›´ã€‚è¯·æä¾›å‡†ç¡®ã€ç®€æ´ã€æœ‰ä»·å€¼çš„åˆ†ææŠ¥å‘Šã€‚"
                max_tokens = 500
                temperature = 0.2

            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": system_content
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=max_tokens,
                temperature=temperature,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"OpenAI Comprehensive Analysis ({analysis_type}): {ai_summary}")

            # å¯¹äºæ–‡ä»¶å†å²åˆ†æï¼Œå°è¯•ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
            if analysis_type == 'file_history_analysis':
                try:
                    # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆJSON
                    json.loads(ai_summary)
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œç”Ÿæˆä¸€ä¸ªé»˜è®¤çš„ç»“æ„åŒ–å“åº”
                    ai_summary = generate_fallback_file_history_analysis(ai_summary)

            return jsonify({
                "analysis": {
                    "summary": ai_summary,
                }
            })

        except OpenAIError as e:
            print(f"OpenAI API error for comprehensive analysis: {e}")
            if analysis_type == 'file_history_analysis':
                error_summary = generate_fallback_file_history_analysis(f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}")
            else:
                error_summary = f"<p><strong>AIåˆ†ææš‚æ—¶ä¸å¯ç”¨</strong></p><p>é”™è¯¯ä¿¡æ¯ï¼š{str(e)}</p>"
            
            return jsonify({
                "analysis": {
                    "summary": error_summary,
                }
            })
        except Exception as e:
            print(f"Unexpected error during comprehensive analysis: {e}")
            if analysis_type == 'file_history_analysis':
                error_summary = generate_fallback_file_history_analysis("AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            else:
                error_summary = "<p><strong>AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯</strong></p><p>è¯·ç¨åé‡è¯•ã€‚</p>"
            
            return jsonify({
                "analysis": {
                    "summary": error_summary,
                }
            })

    except Exception as e:
        print(f"Error processing comprehensive analysis: {e}")
        return jsonify({"error": "An internal server error occurred during comprehensive analysis"}), 500

def generate_fallback_file_history_analysis(error_message):
    """ç”Ÿæˆæ–‡ä»¶å†å²åˆ†æçš„é™çº§å“åº”"""
    return json.dumps({
        "summary": f"æ–‡ä»¶å†å²åˆ†æï¼š{error_message}",
        "evolutionPattern": "æ–‡ä»¶æ¼”è¿›æ¨¡å¼åˆ†æåŸºäºæäº¤å†å²ï¼Œæ˜¾ç¤ºå¼€å‘æ´»è·ƒåº¦å’Œå˜æ›´é¢‘ç‡ã€‚",
        "keyChanges": [
            "ä¸»è¦çš„åŠŸèƒ½æ·»åŠ å’Œé‡æ„",
            "é‡è¦çš„bugä¿®å¤å’Œæ€§èƒ½ä¼˜åŒ–",
            "æ¥å£å˜æ›´å’Œæ¶æ„è°ƒæ•´"
        ],
        "recommendations": [
            "å»ºè®®å®šæœŸé‡æ„ä»¥ä¿æŒä»£ç è´¨é‡",
            "è€ƒè™‘æ·»åŠ æ›´è¯¦ç»†çš„æäº¤ä¿¡æ¯",
            "ä¿æŒä¸€è‡´çš„ä»£ç é£æ ¼å’Œè§„èŒƒ",
            "é€‚æ—¶è¿›è¡Œæ€§èƒ½ä¼˜åŒ–å’Œå®‰å…¨æ›´æ–°"
        ]
    }, ensure_ascii=False)

@app.route('/analyze_file_history', methods=['POST'])
def analyze_file_history():
    """ä¸“é—¨å¤„ç†æ–‡ä»¶å†å²åˆ†æçš„ç«¯ç‚¹"""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OpenAI APIé…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        file_path = data.get('file_path', 'æœªçŸ¥æ–‡ä»¶')
        prompt = data.get('file_diff', '')  # æ–‡ä»¶å†å²åˆ†æçš„å®Œæ•´æç¤º
        
        if not prompt:
            return jsonify({"error": "Missing analysis prompt"}), 400
        
        print(f"Received file history analysis request for: {file_path}")
        
        # ä¼˜åŒ–åçš„æ–‡ä»¶å†å²åˆ†ææç¤ºè¯
        enhanced_prompt = f"""
è¯·å¯¹ä»¥ä¸‹æ–‡ä»¶çš„ç‰ˆæœ¬æ¼”è¿›å†å²è¿›è¡Œæ·±åº¦åˆ†æï¼š

{prompt}

è¦æ±‚ï¼šä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼š

{{
    "summary": "è¯¥æ–‡ä»¶ä»å¼€å§‹åˆ°ç°åœ¨çš„æ•´ä½“æ¼”è¿›æ€»ç»“ï¼ŒåŒ…æ‹¬ä¸»è¦å‘å±•è¶‹åŠ¿å’Œç›®çš„",
    "evolutionPattern": "æ–‡ä»¶çš„æ¼”è¿›æ¨¡å¼åˆ†æï¼ŒåŒ…æ‹¬å¼€å‘æ´»è·ƒåº¦ã€å˜æ›´é¢‘ç‡ã€è´¡çŒ®è€…åä½œæ¨¡å¼ç­‰",
    "keyChanges": [
        "ç¬¬ä¸€ä¸ªé‡è¦çš„å…³é”®å˜æ›´ç‚¹",
        "ç¬¬äºŒä¸ªé‡è¦çš„å…³é”®å˜æ›´ç‚¹",
        "ç¬¬ä¸‰ä¸ªé‡è¦çš„å…³é”®å˜æ›´ç‚¹"
    ],
    "recommendations": [
        "ç¬¬ä¸€ä¸ªä¼˜åŒ–å»ºè®®",
        "ç¬¬äºŒä¸ªä¼˜åŒ–å»ºè®®",
        "ç¬¬ä¸‰ä¸ªä¼˜åŒ–å»ºè®®"
    ]
}}

æ³¨æ„äº‹é¡¹ï¼š
1. å¿…é¡»ä¸¥æ ¼è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
2. keyChangeså’Œrecommendationså¿…é¡»æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œæ¯é¡¹ä¸è¶…è¿‡35å­—
3. summaryå’ŒevolutionPatternä¸ºå­—ç¬¦ä¸²ï¼Œä¸è¶…è¿‡80å­—
4. ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€ä¸“ä¸šä¸”æ˜“æ‡‚
5. ä¸è¦æ·»åŠ ```json```ä»£ç å—åŒ…è£…
6. åŸºäºå®é™…æäº¤å†å²æä¾›æœ‰ä»·å€¼çš„åˆ†æ
"""

        try:
            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç æ¼”è¿›åˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬æˆ–æ ¼å¼åŒ–ã€‚"
                    },
                    {
                        "role": "user",
                        "content": enhanced_prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=400,
                temperature=0.2,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"File History Analysis Raw Response for {file_path}: {ai_summary}")

            # å°è¯•éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSON
            try:
                import json
                test_parse = json.loads(ai_summary)
                if not all(key in test_parse for key in ['summary', 'evolutionPattern', 'keyChanges', 'recommendations']):
                    raise ValueError("Missing required fields in AI response")
                print(f"File History Analysis JSON validation passed for {file_path}")
            except (json.JSONDecodeError, ValueError) as parse_error:
                print(f"AI returned invalid JSON for {file_path}, using fallback: {parse_error}")
                ai_summary = generate_fallback_file_history_json(file_path)

            return jsonify({
                "analysis": {
                    "summary": ai_summary,
                }
            })

        except OpenAIError as e:
            print(f"OpenAI API error for file history analysis: {e}")
            fallback_analysis = generate_fallback_file_history_json(file_path)
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })
        except Exception as e:
            print(f"Unexpected error during file history analysis: {e}")
            fallback_analysis = generate_fallback_file_history_json(file_path)
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })

    except Exception as e:
        print(f"Error processing file history analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def generate_fallback_file_history_json(file_path):
    """ç”Ÿæˆå¤‡ç”¨çš„JSONæ ¼å¼æ–‡ä»¶å†å²åˆ†æ"""
    file_name = file_path.split('/')[-1] if '/' in file_path else file_path
    return json.dumps({
        "summary": f"æ–‡ä»¶ {file_name} ç»å†äº†å¤šæ¬¡ä¿®æ”¹å’Œæ¼”è¿›ï¼Œæ˜¯é¡¹ç›®çš„é‡è¦ç»„æˆéƒ¨åˆ†",
        "evolutionPattern": "è¯¥æ–‡ä»¶åœ¨å¼€å‘è¿‡ç¨‹ä¸­æŒç»­æ”¹è¿›ï¼Œä½“ç°äº†é¡¹ç›®çš„è¿­ä»£å‘å±•ç‰¹ç‚¹",
        "keyChanges": [
            "æ–‡ä»¶ç»“æ„å’ŒåŠŸèƒ½çš„é€æ­¥å®Œå–„",
            "ä»£ç è´¨é‡å’Œæ€§èƒ½çš„æŒç»­ä¼˜åŒ–",
            "æ–°åŠŸèƒ½çš„æ·»åŠ å’Œæ—§åŠŸèƒ½çš„æ”¹è¿›"
        ],
        "recommendations": [
            "å®šæœŸæ£€æŸ¥ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§",
            "ä¿æŒè‰¯å¥½çš„æ–‡æ¡£å’Œæ³¨é‡Šä¹ æƒ¯",
            "è€ƒè™‘é‡æ„å¤æ‚çš„ä»£ç æ®µä»¥æå‡å¯è¯»æ€§"
        ]
    }, ensure_ascii=False)

@app.route('/analyze_file_version_comparison', methods=['POST'])
def analyze_file_version_comparison():
    """ä¸“é—¨å¤„ç†æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æçš„ç«¯ç‚¹"""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OpenAI APIé…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        file_path = data.get('file_path', 'æœªçŸ¥æ–‡ä»¶')
        prompt = data.get('file_diff', '')  # æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æçš„å®Œæ•´æç¤º
        
        if not prompt:
            return jsonify({"error": "Missing analysis prompt"}), 400
        
        print(f"Received file version comparison analysis request for: {file_path}")
        
        try:
            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç ç‰ˆæœ¬æ¯”è¾ƒåˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬æˆ–æ ¼å¼åŒ–ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=500,
                temperature=0.3,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"File Version Comparison Analysis Raw Response for {file_path}: {ai_summary}")

            # å°è¯•éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSON
            try:
                import json
                test_parse = json.loads(ai_summary)
                required_fields = ['summary', 'changeType', 'impactAnalysis', 'keyModifications', 'recommendations']
                if not all(key in test_parse for key in required_fields):
                    raise ValueError("Missing required fields in AI response")
                print(f"File Version Comparison Analysis JSON validation passed for {file_path}")
            except (json.JSONDecodeError, ValueError) as parse_error:
                print(f"AI returned invalid JSON for {file_path}, using fallback: {parse_error}")
                ai_summary = generate_fallback_file_version_comparison_json(file_path)

            return jsonify({
                "analysis": {
                    "summary": ai_summary,
                }
            })

        except OpenAIError as e:
            print(f"OpenAI API error for file version comparison analysis: {e}")
            fallback_analysis = generate_fallback_file_version_comparison_json(file_path)
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })
        except Exception as e:
            print(f"Unexpected error during file version comparison analysis: {e}")
            fallback_analysis = generate_fallback_file_version_comparison_json(file_path)
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })

    except Exception as e:
        print(f"Error processing file version comparison analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def generate_fallback_file_version_comparison_json(file_path):
    """ç”Ÿæˆå¤‡ç”¨çš„JSONæ ¼å¼æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æ"""
    file_name = file_path.split('/')[-1] if '/' in file_path else file_path
    return json.dumps({
        "summary": f"æ–‡ä»¶ {file_name} åœ¨ä¸¤ä¸ªç‰ˆæœ¬ä¹‹é—´å‘ç”Ÿäº†å˜æ›´",
        "changeType": "ä»£ç ä¿®æ”¹",
        "impactAnalysis": "æ­¤æ¬¡å˜æ›´å¯¹æ–‡ä»¶å†…å®¹äº§ç”Ÿäº†å½±å“ï¼Œéœ€è¦è¿›ä¸€æ­¥è¯„ä¼°å…·ä½“çš„åŠŸèƒ½æ€§å½±å“",
        "keyModifications": [
            "æ–‡ä»¶å†…å®¹åœ¨ä¸¤ä¸ªç‰ˆæœ¬é—´å­˜åœ¨å·®å¼‚",
            "å…·ä½“å˜æ›´éœ€è¦æŸ¥çœ‹diffå†…å®¹",
            "å»ºè®®å®¡æŸ¥å˜æ›´çš„ä¸šåŠ¡é€»è¾‘å½±å“"
        ],
        "recommendations": [
            "ä»”ç»†æ£€æŸ¥å˜æ›´å†…å®¹ç¡®ä¿ç¬¦åˆé¢„æœŸ",
            "è€ƒè™‘è¿›è¡Œç›¸å…³æµ‹è¯•éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§"
        ]
    }, ensure_ascii=False)

@app.route('/analyze_batch', methods=['POST'])
def analyze_batch():
    """æ‰¹é‡åˆ†æå¤šä¸ªæ–‡ä»¶çš„å·®å¼‚"""
    if not openai_client:
        return jsonify({
            "error": "AI analysis disabled: OPENAI_API_KEY not configured."
        }), 503

    try:
        data = request.get_json()
        if not data or 'files' not in data:
            return jsonify({"error": "Missing files array in request"}), 400
        
        files = data['files']
        if not isinstance(files, list) or len(files) == 0:
            return jsonify({"error": "Files must be a non-empty array"}), 400
        
        # é™åˆ¶æ‰¹é‡å¤„ç†çš„æ–‡ä»¶æ•°é‡
        if len(files) > 10:
            return jsonify({"error": "Too many files in batch (max 10)"}), 400
        
        results = []
        for file_data in files:
            if 'file_path' not in file_data or 'file_diff' not in file_data:
                results.append({
                    "file_path": file_data.get('file_path', 'unknown'),
                    "analysis": None,
                    "error": "Missing file_path or file_diff"
                })
                continue
            
            # é‡ç”¨å•æ–‡ä»¶åˆ†æé€»è¾‘
            try:
                # è¿™é‡Œå¯ä»¥è°ƒç”¨analyze_diffçš„æ ¸å¿ƒé€»è¾‘
                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›ä¸€ä¸ªç®€å•çš„åˆ†æ
                file_path = file_data['file_path']
                file_name = file_path.split('/')[-1]
                
                results.append({
                    "file_path": file_path,
                    "analysis": {
                        "summary": f"{file_name}: æ–‡ä»¶å·²ä¿®æ”¹ï¼ŒåŒ…å«ä»£ç å˜æ›´ã€‚"
                    },
                    "error": None
                })
            except Exception as e:
                results.append({
                    "file_path": file_data['file_path'],
                    "analysis": None,
                    "error": str(e)
                })
        
        return jsonify({"results": results})
        
    except Exception as e:
        print(f"Error processing batch request: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

if __name__ == '__main__':
    print("Starting AI Analysis Server...")
    print("="*50)
    print("ğŸ”§ æœåŠ¡å™¨é…ç½®:")
    print(f"   - æœ¬åœ°è®¿é—®: http://127.0.0.1:5111")
    print(f"   - å±€åŸŸç½‘è®¿é—®: http://[ä½ çš„å†…ç½‘IP]:5111") 
    print(f"   - å¤–ç½‘è®¿é—®: http://[ä½ çš„å…¬ç½‘IP]:5111")
    print("="*50)
    print("ğŸ“ å¯ç”¨ç«¯ç‚¹:")
    print(f"   - å¥åº·æ£€æŸ¥: /health")
    print(f"   - å·®å¼‚åˆ†æ: /analyze_diff") 
    print(f"   - æ–‡ä»¶å†å²: /analyze_file_history")
    print(f"   - ç‰ˆæœ¬æ¯”è¾ƒ: /analyze_file_version_comparison")
    print(f"   - æ‰¹é‡åˆ†æ: /analyze_batch")
    print("="*50)
    print("âš ï¸  å®‰å…¨æç¤º:")
    print("   - å½“å‰é…ç½®å…è®¸æ‰€æœ‰IPè®¿é—®")
    print("   - ç”Ÿäº§ç¯å¢ƒè¯·é…ç½®é˜²ç«å¢™è§„åˆ™")
    print("   - å»ºè®®è®¾ç½®APIè®¿é—®é™åˆ¶")
    print("="*50)
    
    # è·å–å¹¶æ˜¾ç¤ºæœ¬æœºIPåœ°å€
    try:
        import socket
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        print(f"ğŸŒ æœ¬æœºIPåœ°å€: {local_ip}")
        print(f"   å±€åŸŸç½‘è®¿é—®é“¾æ¥: http://{local_ip}:5111/health")
    except:
        print("ğŸŒ æ— æ³•è·å–æœ¬æœºIPï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹")
    
    print("="*50)
    print("ğŸš€ æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    
    # Note: Use '0.0.0.0' to be accessible from the extension container
    # Use a specific port, e.g., 5111
    app.run(host='0.0.0.0', port=5111, debug=True)  # ç”Ÿäº§ç¯å¢ƒå»ºè®®debug=False 