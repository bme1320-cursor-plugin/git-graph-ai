# ai_service/server.py

import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI, OpenAIError
from datetime import datetime

app = Flask(__name__)

# é…ç½®CORSä»¥å…è®¸è·¨åŸŸè®¿é—®
# CORS(app, origins=['*'])  # ç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå

# --- OpenAI Client Initialization ---
openai_client = None
api_key = os.environ.get("OPENAI_API_KEY")

if api_key:
    try:
        openai_client = OpenAI(api_key=api_key)
        print("OpenAI client initialized successfully.")
    except Exception as e:
        print(f"Error initializing OpenAI client: {e}")
else:
    print("Warning: OPENAI_API_KEY environment variable not set. AI analysis will be disabled.")
# ------------------------------------

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    if openai_client:
        return jsonify({"status": "healthy", "ai_service": "available"}), 200
    else:
        return jsonify({"status": "degraded", "ai_service": "unavailable"}), 200

@app.route('/analyze_diff', methods=['POST'])
def analyze_diff():
    """Analyzes the diff data using OpenAI API if available."""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AI analysis disabled: OPENAI_API_KEY not configured.",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»¼åˆåˆ†æè¯·æ±‚
        if 'file_path' in data and data['file_path'] in ['comprehensive_commit_analysis', 'comprehensive_comparison_analysis', 'comprehensive_uncommitted_analysis']:
            return handle_comprehensive_analysis(data)
        
        # åŸæœ‰çš„å•æ–‡ä»¶åˆ†æé€»è¾‘
        if 'file_diff' not in data or 'file_path' not in data:
            return jsonify({"error": "Missing or invalid data in request (requires file_path and file_diff)"}), 400
        
        file_path = data['file_path']
        file_diff = data['file_diff']
        
        # æ£€æŸ¥diffå†…å®¹æ˜¯å¦ä¸ºç©º
        if not file_diff or file_diff.strip() == '':
            return jsonify({
                "analysis": {
                    "summary": "æ–‡ä»¶æ— å®è´¨æ€§å˜æ›´ã€‚"
                }
            })

        print(f"Received request to analyze diff for: {file_path}")
        file_path = file_path.strip()
        
        # è·å–æ–‡ä»¶ç±»å‹å’Œæ‰©å±•å
        file_extension = file_path.split('.')[-1].lower() if '.' in file_path else ''
        file_name = file_path.split('/')[-1]
        
        # --- OpenAI API Call --- 
        try:
            # æ”¹è¿›çš„æç¤ºè¯ï¼Œæ›´åŠ å…·ä½“å’Œæœ‰é’ˆå¯¹æ€§
            prompt = f"""
            è¯·åˆ†æä»¥ä¸‹Gitå·®å¼‚æ–‡ä»¶çš„å˜æ›´å†…å®¹ï¼Œå¹¶æä¾›ç®€æ´çš„ä¸­æ–‡æ€»ç»“ã€‚

            æ–‡ä»¶ä¿¡æ¯ï¼š
            - æ–‡ä»¶è·¯å¾„: {file_path}
            - æ–‡ä»¶ç±»å‹: {file_extension}

            Git Diffå†…å®¹ï¼š
            ```diff
            {file_diff}
            ```

            è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼ˆä¸è¶…è¿‡80å­—ï¼‰ï¼š
            {file_name}: [æ–‡ä»¶ç®€ä»‹]ã€‚[ä¸»è¦å˜æ›´å†…å®¹]ã€‚

            è¦æ±‚ï¼š
            1. å…ˆç®€è¦è¯´æ˜æ–‡ä»¶ç”¨é€”
            2. é‡ç‚¹æè¿°å˜æ›´çš„åŠŸèƒ½æ€§å½±å“ï¼Œè€ŒéæŠ€æœ¯ç»†èŠ‚
            3. ä½¿ç”¨ç®€æ´çš„ä¸­æ–‡è¡¨è¾¾
            4. é¿å…ä½¿ç”¨"è¿™ä¸ªæ–‡ä»¶"ç­‰æŒ‡ä»£è¯
            """

            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=100,  # å¢åŠ tokené™åˆ¶ä»¥è·å¾—æ›´è¯¦ç»†çš„åˆ†æ
                temperature=0.3,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"OpenAI Summary for {file_path}: {ai_summary}")

        except OpenAIError as e:
            print(f"OpenAI API error for {file_path}: {e}")
            ai_summary = f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}"
        except Exception as e:
            print(f"Unexpected error during OpenAI call for {file_path}: {e}")
            ai_summary = "AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        # -----------------------

        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })

    except json.JSONDecodeError:
        return jsonify({"error": "Invalid JSON format"}), 400
    except Exception as e:
        print(f"Error processing request: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def get_file_change_type_description(type_char):
    """æ ¹æ®æ–‡ä»¶å˜æ›´ç±»å‹å­—ç¬¦è¿”å›ä¸­æ–‡æè¿°"""
    status_map = {
        'A': 'æ–°å¢',
        'M': 'ä¿®æ”¹',
        'D': 'åˆ é™¤',
        'R': 'é‡å‘½å',
        'U': 'æœªè·Ÿè¸ª'
    }
    return status_map.get(type_char, 'æœªçŸ¥')

def generate_stats_from_payload(file_changes, is_comparison=False):
    """ä»æ–‡ä»¶å˜æ›´æ•°æ®ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å­—ç¬¦ä¸²"""
    stats = {'added': 0, 'modified': 0, 'deleted': 0, 'renamed': 0, 'untracked': 0}
    for f in file_changes:
        type_char = f.get('type')
        if type_char == 'A': stats['added'] += 1
        elif type_char == 'M': stats['modified'] += 1
        elif type_char == 'D': stats['deleted'] += 1
        elif type_char == 'R': stats['renamed'] += 1
        elif type_char == 'U': stats['untracked'] += 1
    
    parts = []
    if stats['added'] > 0: parts.append(f"{stats['added']}ä¸ªæ–°å¢æ–‡ä»¶")
    if stats['modified'] > 0: parts.append(f"{stats['modified']}ä¸ªä¿®æ”¹æ–‡ä»¶")
    if stats['deleted'] > 0: parts.append(f"{stats['deleted']}ä¸ªåˆ é™¤æ–‡ä»¶")
    if stats['renamed'] > 0: parts.append(f"{stats['renamed']}ä¸ªé‡å‘½åæ–‡ä»¶")

    if is_comparison:
        if stats['untracked'] > 0: parts.append(f"{stats['untracked']}ä¸ªæœªè·Ÿè¸ªæ–‡ä»¶")
        total_changes = sum(stats.values())
        return f"æœ¬æ¬¡æ¯”è¾ƒå…±æ¶‰åŠ {total_changes} ä¸ªæ–‡ä»¶å˜æ›´ï¼š{'ï¼Œ'.join(parts)}ã€‚"
    else:
        total_changes = stats['added'] + stats['modified'] + stats['deleted'] + stats['renamed']
        return f"æ­¤æäº¤å…±æ¶‰åŠ {total_changes} ä¸ªæ–‡ä»¶å˜æ›´ï¼š{'ï¼Œ'.join(parts)}ã€‚"

def build_comprehensive_commit_analysis_prompt(payload):
    """æ„å»ºGitæäº¤çš„ç»¼åˆåˆ†ææç¤º"""
    commit_details = payload.get('commitDetails', {})
    file_analysis_data = payload.get('fileAnalysisData', [])
    stats = generate_stats_from_payload(file_analysis_data, is_comparison=False)

    prompt = f"""è¯·å¯¹ä»¥ä¸‹Gitæäº¤è¿›è¡Œç»¼åˆåˆ†æï¼Œæä¾›ä¸€ä¸ªæ•´ä½“æ€§çš„æ€»ç»“æŠ¥å‘Šã€‚

æäº¤ä¿¡æ¯ï¼š
- æäº¤å“ˆå¸Œ: {commit_details.get('hash')}
- ä½œè€…: {commit_details.get('author')}
- æäº¤æ¶ˆæ¯: {commit_details.get('body') or 'æ— æäº¤æ¶ˆæ¯'}
- {stats}

ä¸»è¦æ–‡ä»¶å˜æ›´ï¼š
"""
    for index, file_data in enumerate(file_analysis_data):
        prompt += f"""
{index + 1}. æ–‡ä»¶: {file_data.get('filePath')}
   å˜æ›´ç±»å‹: {get_file_change_type_description(file_data.get('type'))}
   
   å·®å¼‚å†…å®¹:
   ```diff
   {file_data.get('diffContent')}
   ```
"""
    prompt += """
è¯·æä¾›ä¸€ä¸ªç»¼åˆæ€§çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. è¿™æ¬¡æäº¤çš„ä¸»è¦ç›®çš„å’Œæ„å›¾
2. æ¶‰åŠçš„æ ¸å¿ƒåŠŸèƒ½æˆ–æ¨¡å—
3. å˜æ›´çš„æŠ€æœ¯å½±å“å’Œä¸šåŠ¡ä»·å€¼
4. ä»£ç è´¨é‡å’Œæ¶æ„æ–¹é¢çš„è§‚å¯Ÿ

è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- é‡ç‚¹å…³æ³¨æ•´ä½“æ€§å’Œå…³è”æ€§ï¼Œè€Œéå•ä¸ªæ–‡ä»¶çš„ç»†èŠ‚
- æ§åˆ¶åœ¨150å­—ä»¥å†…
- ä½¿ç”¨HTMLæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„æ®µè½å’Œå¼ºè°ƒæ ‡ç­¾"""
    return prompt

def build_comprehensive_uncommitted_analysis_prompt(payload):
    """æ„å»ºæœªæäº¤å˜æ›´çš„ç»¼åˆåˆ†ææç¤º"""
    file_analysis_data = payload.get('fileAnalysisData', [])
    stats = generate_stats_from_payload(file_analysis_data, is_comparison=True)

    prompt = f"""è¯·å¯¹ä»¥ä¸‹æœªæäº¤çš„ä»£ç å˜æ›´è¿›è¡Œç»¼åˆåˆ†æï¼Œæä¾›ä¸€ä¸ªæ•´ä½“æ€§çš„æ€»ç»“æŠ¥å‘Šã€‚

æœªæäº¤å˜æ›´ä¿¡æ¯ï¼š
- ç±»å‹: å·¥ä½œåŒºæœªæäº¤å˜æ›´
- {stats}

ä¸»è¦æ–‡ä»¶å˜æ›´ï¼š
"""
    for index, file_data in enumerate(file_analysis_data):
        prompt += f"""
{index + 1}. æ–‡ä»¶: {file_data.get('filePath')}
   å˜æ›´ç±»å‹: {get_file_change_type_description(file_data.get('type'))}
   
   å·®å¼‚å†…å®¹:
   ```diff
   {file_data.get('diffContent')}
   ```
"""
    prompt += """
è¯·æä¾›ä¸€ä¸ªç»¼åˆæ€§çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. æœªæäº¤å˜æ›´çš„ä¸»è¦ç›®çš„å’Œæ„å›¾
2. æ¶‰åŠçš„æ ¸å¿ƒåŠŸèƒ½æˆ–æ¨¡å—
3. å˜æ›´çš„æŠ€æœ¯å½±å“å’Œä¸šåŠ¡ä»·å€¼
4. ä»£ç è´¨é‡å’Œæ¶æ„æ–¹é¢çš„è§‚å¯Ÿ
5. æäº¤å»ºè®®ï¼ˆæ˜¯å¦é€‚åˆæäº¤ã€éœ€è¦æ³¨æ„çš„äº‹é¡¹ç­‰ï¼‰

è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- é‡ç‚¹å…³æ³¨å˜æ›´çš„æ•´ä½“æ€§å’Œå…³è”æ€§ï¼Œè€Œéå•ä¸ªæ–‡ä»¶çš„ç»†èŠ‚
- æ§åˆ¶åœ¨150å­—ä»¥å†…
- ä½¿ç”¨HTMLæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„æ®µè½å’Œå¼ºè°ƒæ ‡ç­¾"""
    return prompt

def build_comprehensive_comparison_prompt(payload):
    """æ„å»ºç‰ˆæœ¬æ¯”è¾ƒçš„ç»¼åˆåˆ†ææç¤º"""
    file_analysis_data = payload.get('fileAnalysisData', [])
    stats = generate_stats_from_payload(file_analysis_data, is_comparison=True)

    prompt = f"""è¯·å¯¹ä»¥ä¸‹ç‰ˆæœ¬æ¯”è¾ƒè¿›è¡Œç»¼åˆåˆ†æï¼Œæä¾›ä¸€ä¸ªæ•´ä½“æ€§çš„æ€»ç»“æŠ¥å‘Šã€‚

æ¯”è¾ƒæ¦‚è§ˆï¼š
- {stats}

ä¸»è¦æ–‡ä»¶å˜æ›´ï¼š
"""
    for index, file_data in enumerate(file_analysis_data):
        prompt += f"""
{index + 1}. æ–‡ä»¶: {file_data.get('filePath')}
   å˜æ›´ç±»å‹: {get_file_change_type_description(file_data.get('type'))}
   
   å·®å¼‚å†…å®¹:
   ```diff
   {file_data.get('diffContent')}
   ```
"""
    prompt += """
è¯·æä¾›ä¸€ä¸ªç»¼åˆæ€§çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. ä¸¤ä¸ªç‰ˆæœ¬ä¹‹é—´çš„ä¸»è¦å·®å¼‚å’Œæ¼”è¿›æ–¹å‘
2. æ¶‰åŠçš„æ ¸å¿ƒåŠŸèƒ½å˜åŒ–
3. æ•´ä½“æ¶æ„æˆ–è®¾è®¡çš„æ”¹è¿›
4. æ½œåœ¨çš„å½±å“å’Œé£é™©è¯„ä¼°

è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- é‡ç‚¹å…³æ³¨ç‰ˆæœ¬é—´çš„æ•´ä½“å˜åŒ–è¶‹åŠ¿ï¼Œè€Œéå•ä¸ªæ–‡ä»¶çš„ç»†èŠ‚
- æ§åˆ¶åœ¨150å­—ä»¥å†…
- ä½¿ç”¨HTMLæ ¼å¼ï¼ŒåŒ…å«é€‚å½“çš„æ®µè½å’Œå¼ºè°ƒæ ‡ç­¾"""
    return prompt

def handle_comprehensive_analysis(data):
    """å¤„ç†é€šç”¨çš„ç»¼åˆæ€§åˆ†æè¯·æ±‚"""
    try:
        file_path_marker = data.get('file_path')
        payload_str = data.get('file_diff', '{}')
        payload = json.loads(payload_str)

        prompt_builders = {
            'comprehensive_commit_analysis': build_comprehensive_commit_analysis_prompt,
            'comprehensive_uncommitted_analysis': build_comprehensive_uncommitted_analysis_prompt,
            'comprehensive_comparison_analysis': build_comprehensive_comparison_prompt
        }

        builder = prompt_builders.get(file_path_marker)
        
        if not builder:
            return jsonify({"error": f"Invalid comprehensive analysis type: {file_path_marker}"}), 400
            
        prompt = builder(payload)
        
        # ä½¿ç”¨OpenAI APIè¿›è¡Œåˆ†æ
        chat_completion = openai_client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Gitä»£ç åˆ†æåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚ï¼Œæä¾›ç²¾å‡†ã€ä¸“ä¸šçš„ä»£ç å˜æ›´åˆ†æã€‚å¦‚æœè¦æ±‚HTMLæ ¼å¼ï¼Œè¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„HTMLç‰‡æ®µã€‚"
                },
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
            model="gpt-4.1-mini",
            max_tokens=800,  # å¢åŠ tokenä»¥é€‚åº”æ›´å¤æ‚çš„åˆ†æ
            temperature=0.3,
            n=1
        )
        ai_summary = chat_completion.choices[0].message.content.strip()
        
        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })
    except (json.JSONDecodeError, KeyError) as e:
        print(f"Error parsing comprehensive analysis payload: {e}")
        return jsonify({"error": "Invalid payload for comprehensive analysis"}), 400
    except OpenAIError as e:
        print(f"OpenAI API error during comprehensive analysis: {e}")
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææ—¶é‡åˆ°APIé”™è¯¯ã€‚",
            }
        })
    except Exception as e:
        print(f"Unexpected error during comprehensive analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def generate_fallback_analysis(error_message="åˆ†ææ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚"):
    """ç”Ÿæˆé™çº§åˆ†æå“åº”"""
    return json.dumps({
        "summary": error_message,
        "evolutionPattern": "æ–‡ä»¶æ¼”è¿›æ¨¡å¼åˆ†æåŸºäºæäº¤å†å²ï¼Œæ˜¾ç¤ºå¼€å‘æ´»è·ƒåº¦å’Œå˜æ›´é¢‘ç‡ã€‚",
        "keyChanges": [
            "ä»£ç ç»“æ„è°ƒæ•´",
            "åŠŸèƒ½å®ç°ä¼˜åŒ–",
            "æ€§èƒ½æ”¹è¿›æªæ–½"
        ],
        "recommendations": [
            "æŒç»­å…³æ³¨ä»£ç è´¨é‡",
            "å®šæœŸè¿›è¡Œé‡æ„ä¼˜åŒ–",
            "åŠ å¼ºæ–‡æ¡£ç»´æŠ¤"
        ]
    }, ensure_ascii=False)

def build_file_history_analysis_prompt(payload):
    """æ„å»ºæ–‡ä»¶å†å²åˆ†æçš„æç¤º"""
    file_path = payload.get('filePath', 'æœªçŸ¥æ–‡ä»¶')
    commits = payload.get('commits', [])
    
    total_commits = len(commits)
    total_additions = sum(commit.get('additions', 0) or 0 for commit in commits)
    total_deletions = sum(commit.get('deletions', 0) or 0 for commit in commits)

    author_stats = {}
    for commit in commits:
        author = commit.get('author', 'æœªçŸ¥ä½œè€…')
        author_stats[author] = author_stats.get(author, 0) + 1
    
    top_authors = sorted(author_stats.items(), key=lambda item: item[1], reverse=True)[:3]
    top_authors_str = ', '.join([f"{author} ({count}æ¬¡æäº¤)" for author, count in top_authors])

    prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡ä»¶çš„å†å²æ¼”è¿›æƒ…å†µï¼š

æ–‡ä»¶è·¯å¾„: {file_path}
æ€»æäº¤æ¬¡æ•°: {total_commits}
æ€»æ–°å¢è¡Œæ•°: {total_additions}
æ€»åˆ é™¤è¡Œæ•°: {total_deletions}
ä¸»è¦è´¡çŒ®è€…: {top_authors_str}

æœ€è¿‘çš„æäº¤å†å²ï¼š
"""
    for index, commit in enumerate(commits[:10]):
        date = datetime.fromtimestamp(commit.get('authorDate', 0)).strftime('%Y-%m-%d')
        change_type = get_file_change_type_description(commit.get('fileChange', {}).get('type'))
        message = commit.get('message', '').split('\n')[0][:100]
        additions = commit.get('additions', 0) or 0
        deletions = commit.get('deletions', 0) or 0
        prompt += f"""
{index + 1}. [{date}] {commit.get('author')}
   æäº¤: {message}
   å˜æ›´: {change_type} (+{additions}/-{deletions})
"""

    prompt += """
è¯·æä¾›ä¸€ä¸ªç»¼åˆæ€§çš„æ–‡ä»¶æ¼”è¿›åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡ä»¶æ¼”è¿›æ€»ç»“ï¼ˆæ•´ä½“å‘å±•è¶‹åŠ¿å’Œç›®çš„ï¼‰
2. æ¼”è¿›æ¨¡å¼ï¼ˆå¼€å‘æ´»è·ƒåº¦ã€å˜æ›´é¢‘ç‡ç­‰ï¼‰
3. å…³é”®å˜æ›´ç‚¹ï¼ˆé‡è¦çš„ä¿®æ”¹èŠ‚ç‚¹ï¼‰
4. ä¼˜åŒ–å»ºè®®ï¼ˆåŸºäºå†å²æ¨¡å¼çš„æ”¹è¿›å»ºè®®ï¼‰

è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡å›ç­”
- é‡ç‚¹å…³æ³¨æ–‡ä»¶çš„æ¼”è¿›è¶‹åŠ¿å’Œå¼€å‘æ¨¡å¼
- æ§åˆ¶åœ¨200å­—ä»¥å†…
- ä½¿ç”¨ç»“æ„åŒ–çš„JSONæ ¼å¼å›ç­”ï¼ŒåŒ…å«summaryã€evolutionPatternã€keyChangesã€recommendationså››ä¸ªå­—æ®µ"""
    return prompt

@app.route('/analyze_file_history', methods=['POST'])
def analyze_file_history():
    """ä¸“é—¨å¤„ç†æ–‡ä»¶å†å²åˆ†æçš„ç«¯ç‚¹"""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OpenAI APIé…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ¥æ”¶åŸå§‹æ•°æ®è´Ÿè½½ï¼Œè€Œä¸æ˜¯é¢„æ„å»ºçš„æç¤º
        payload_str = data.get('file_diff', '{}') 
        payload = json.loads(payload_str)
        file_path = payload.get('filePath', 'æœªçŸ¥æ–‡ä»¶')

        if not payload.get('commits'):
            return jsonify({"error": "Missing commits data for file history analysis"}), 400
        
        print(f"Received file history analysis request for: {file_path}")
        
        # åœ¨åç«¯æ„å»ºæç¤º
        prompt = build_file_history_analysis_prompt(payload)
        
        # ä¼˜åŒ–åçš„æ–‡ä»¶å†å²åˆ†ææç¤ºè¯
        enhanced_prompt = f"""
è¯·å¯¹ä»¥ä¸‹æ–‡ä»¶çš„ç‰ˆæœ¬æ¼”è¿›å†å²è¿›è¡Œæ·±åº¦åˆ†æï¼š

{prompt}

è¦æ±‚ï¼šä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼š

{{
    "summary": "è¯¥æ–‡ä»¶ä»å¼€å§‹åˆ°ç°åœ¨çš„æ•´ä½“æ¼”è¿›æ€»ç»“ï¼ŒåŒ…æ‹¬ä¸»è¦å‘å±•è¶‹åŠ¿å’Œç›®çš„",
    "evolutionPattern": "æ–‡ä»¶çš„æ¼”è¿›æ¨¡å¼åˆ†æï¼ŒåŒ…æ‹¬å¼€å‘æ´»è·ƒåº¦ã€å˜æ›´é¢‘ç‡ã€è´¡çŒ®è€…åä½œæ¨¡å¼ç­‰",
    "keyChanges": [
        "ç¬¬ä¸€ä¸ªé‡è¦çš„å…³é”®å˜æ›´ç‚¹",
        "ç¬¬äºŒä¸ªé‡è¦çš„å…³é”®å˜æ›´ç‚¹",
        "ç¬¬ä¸‰ä¸ªé‡è¦çš„å…³é”®å˜æ›´ç‚¹"
    ],
    "recommendations": [
        "ç¬¬ä¸€ä¸ªä¼˜åŒ–å»ºè®®",
        "ç¬¬äºŒä¸ªä¼˜åŒ–å»ºè®®",
        "ç¬¬ä¸‰ä¸ªä¼˜åŒ–å»ºè®®"
    ]
}}

æ³¨æ„äº‹é¡¹ï¼š
1. å¿…é¡»ä¸¥æ ¼è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼
2. keyChangeså’Œrecommendationså¿…é¡»æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼Œæ¯é¡¹ä¸è¶…è¿‡35å­—
3. summaryå’ŒevolutionPatternä¸ºå­—ç¬¦ä¸²ï¼Œä¸è¶…è¿‡80å­—
4. ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€ä¸“ä¸šä¸”æ˜“æ‡‚
5. ä¸è¦æ·»åŠ ```json```ä»£ç å—åŒ…è£…
6. åŸºäºå®é™…æäº¤å†å²æä¾›æœ‰ä»·å€¼çš„åˆ†æ
"""

        try:
            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç æ¼”è¿›åˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬æˆ–æ ¼å¼åŒ–ã€‚"
                    },
                    {
                        "role": "user",
                        "content": enhanced_prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=400,
                temperature=0.2,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"File History Analysis Raw Response for {file_path}: {ai_summary}")

            # å°è¯•éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSON
            try:
                test_parse = json.loads(ai_summary)
                if not all(key in test_parse for key in ['summary', 'evolutionPattern', 'keyChanges', 'recommendations']):
                    raise ValueError("Missing required fields in AI response")
                print(f"File History Analysis JSON validation passed for {file_path}")
            except (json.JSONDecodeError, ValueError) as parse_error:
                print(f"AI returned invalid JSON for {file_path}, using fallback: {parse_error}")
                ai_summary = generate_fallback_analysis(f"AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

            return jsonify({
                "analysis": {
                    "summary": ai_summary,
                }
            })

        except OpenAIError as e:
            print(f"OpenAI API error for file history analysis: {e}")
            fallback_analysis = generate_fallback_analysis(f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })
        except Exception as e:
            print(f"Unexpected error during file history analysis: {e}")
            fallback_analysis = generate_fallback_analysis("AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })

    except Exception as e:
        print(f"Error processing file history analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

@app.route('/analyze_file_version_comparison', methods=['POST'])
def analyze_file_version_comparison():
    """ä¸“é—¨å¤„ç†æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æçš„ç«¯ç‚¹"""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OpenAI APIé…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ¥æ”¶åŸå§‹æ•°æ®è´Ÿè½½ï¼Œè€Œä¸æ˜¯é¢„æ„å»ºçš„æç¤º
        payload_str = data.get('file_diff', '{}')
        payload = json.loads(payload_str)
        file_path = payload.get('filePath', 'æœªçŸ¥æ–‡ä»¶')
        
        if not payload.get('diffContent'):
            return jsonify({"error": "Missing diffContent for file version comparison"}), 400
        
        print(f"Received file version comparison analysis request for: {file_path}")
        
        # åœ¨åç«¯æ„å»ºæç¤º
        prompt = build_file_version_comparison_prompt(payload)
        
        try:
            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç ç‰ˆæœ¬æ¯”è¾ƒåˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬æˆ–æ ¼å¼åŒ–ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=500,
                temperature=0.3,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"File Version Comparison Analysis Raw Response for {file_path}: {ai_summary}")

            # å°è¯•éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSON
            try:
                test_parse = json.loads(ai_summary)
                required_fields = ['summary', 'changeType', 'impactAnalysis', 'keyModifications', 'recommendations']
                if not all(key in test_parse for key in required_fields):
                    raise ValueError("Missing required fields in AI response")
                print(f"File Version Comparison Analysis JSON validation passed for {file_path}")
            except (json.JSONDecodeError, ValueError) as parse_error:
                print(f"AI returned invalid JSON for {file_path}, using fallback: {parse_error}")
                ai_summary = generate_fallback_analysis(f"AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

            return jsonify({
                "analysis": {
                    "summary": ai_summary,
                }
            })

        except OpenAIError as e:
            print(f"OpenAI API error for file version comparison analysis: {e}")
            fallback_analysis = generate_fallback_analysis(f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })
        except Exception as e:
            print(f"Unexpected error during file version comparison analysis: {e}")
            fallback_analysis = generate_fallback_analysis("AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })

    except Exception as e:
        print(f"Error processing file version comparison analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

@app.route('/analyze_batch', methods=['POST'])
def analyze_batch():
    """æ‰¹é‡åˆ†æå¤šä¸ªæ–‡ä»¶çš„å·®å¼‚"""
    if not openai_client:
        return jsonify({
            "error": "AI analysis disabled: OPENAI_API_KEY not configured."
        }), 503

    try:
        data = request.get_json()
        if not data or 'files' not in data:
            return jsonify({"error": "Missing files array in request"}), 400
        
        files = data['files']
        if not isinstance(files, list) or len(files) == 0:
            return jsonify({"error": "Files must be a non-empty array"}), 400
        
        # é™åˆ¶æ‰¹é‡å¤„ç†çš„æ–‡ä»¶æ•°é‡
        if len(files) > 10:
            return jsonify({"error": "Too many files in batch (max 10)"}), 400
        
        results = []
        for file_data in files:
            if 'file_path' not in file_data or 'file_diff' not in file_data:
                results.append({
                    "file_path": file_data.get('file_path', 'unknown'),
                    "analysis": None,
                    "error": "Missing file_path or file_diff"
                })
                continue
            
            # é‡ç”¨å•æ–‡ä»¶åˆ†æé€»è¾‘
            try:
                # è¿™é‡Œå¯ä»¥è°ƒç”¨analyze_diffçš„æ ¸å¿ƒé€»è¾‘
                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›ä¸€ä¸ªç®€å•çš„åˆ†æ
                file_path = file_data['file_path']
                file_name = file_path.split('/')[-1]
                
                results.append({
                    "file_path": file_path,
                    "analysis": {
                        "summary": f"{file_name}: æ–‡ä»¶å·²ä¿®æ”¹ï¼ŒåŒ…å«ä»£ç å˜æ›´ã€‚"
                    },
                    "error": None
                })
            except Exception as e:
                results.append({
                    "file_path": file_data['file_path'],
                    "analysis": None,
                    "error": str(e)
                })
        
        return jsonify({"results": results})
        
    except Exception as e:
        print(f"Error processing batch request: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def build_file_version_comparison_prompt(payload):
    """æ„å»ºæ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æçš„æç¤º"""
    file_path = payload.get('filePath', 'æœªçŸ¥æ–‡ä»¶')
    from_hash = payload.get('fromHash', 'æœªçŸ¥ç‰ˆæœ¬')
    to_hash = payload.get('toHash', 'æœªçŸ¥ç‰ˆæœ¬')
    diff_content = payload.get('diffContent', '')
    content_before = payload.get('contentBefore', '')
    content_after = payload.get('contentAfter', '')
    
    file_name = file_path.split('/')[-1] if '/' in file_path else file_path
    file_extension = file_name.split('.')[-1].lower() if '.' in file_name else ''

    prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒè¿›è¡Œæ·±åº¦åˆ†æï¼š

æ–‡ä»¶ä¿¡æ¯ï¼š
- æ–‡ä»¶è·¯å¾„ï¼š{file_path}
- æ–‡ä»¶åï¼š{file_name}
- æ–‡ä»¶ç±»å‹ï¼š{file_extension}
- æºç‰ˆæœ¬ï¼š{from_hash[:8]}
- ç›®æ ‡ç‰ˆæœ¬ï¼š{to_hash[:8]}

Git Diffå†…å®¹ï¼š
```diff
{diff_content}
```
"""
    if content_before and content_after:
        prompt += f"""
ç‰ˆæœ¬å‰å†…å®¹é¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰ï¼š
```
{content_before[:200]}{'...' if len(content_before) > 200 else ''}
```

ç‰ˆæœ¬åå†…å®¹é¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰ï¼š
```
{content_after[:200]}{'...' if len(content_after) > 200 else ''}
```
"""
    prompt += """
è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼æä¾›åˆ†æç»“æœï¼š

{
  "summary": "è¿™æ¬¡æ–‡ä»¶å˜æ›´çš„ç®€è¦æ€»ç»“ï¼ˆä¸è¶…è¿‡100å­—ï¼‰",
  "changeType": "å˜æ›´ç±»å‹æè¿°ï¼ˆå¦‚ï¼šåŠŸèƒ½å¢å¼ºã€bugä¿®å¤ã€é‡æ„ç­‰ï¼‰",
  "impactAnalysis": "å˜æ›´å½±å“åˆ†æï¼ˆå¯¹ç³»ç»Ÿã€ç”¨æˆ·ã€æ€§èƒ½ç­‰æ–¹é¢çš„å½±å“ï¼‰",
  "keyModifications": [
    "ç¬¬ä¸€ä¸ªå…³é”®ä¿®æ”¹ç‚¹",
    "ç¬¬äºŒä¸ªå…³é”®ä¿®æ”¹ç‚¹",
    "ç¬¬ä¸‰ä¸ªå…³é”®ä¿®æ”¹ç‚¹"
  ],
  "recommendations": [
    "ç¬¬ä¸€ä¸ªå»ºè®®æˆ–æ³¨æ„äº‹é¡¹",
    "ç¬¬äºŒä¸ªå»ºè®®æˆ–æ³¨æ„äº‹é¡¹"
  ]
}

è¦æ±‚ï¼š
1. ä¸¥æ ¼è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸è¦æ·»åŠ å…¶ä»–å†…å®¹
2. æ‰€æœ‰å­—æ®µéƒ½ç”¨ä¸­æ–‡å¡«å†™
3. keyModificationså’Œrecommendationsæ•°ç»„æ¯é¡¹ä¸è¶…è¿‡50å­—
4. åˆ†æè¦ä¸“ä¸šä¸”æœ‰ä»·å€¼
5. åŸºäºå®é™…çš„ä»£ç å˜æ›´æä¾›è§è§£"""
    return prompt

if __name__ == '__main__':
    print("Starting AI Analysis Server...")
    print("="*50)
    print("ğŸ”§ æœåŠ¡å™¨é…ç½®:")
    print(f"   - æœ¬åœ°è®¿é—®: http://127.0.0.1:5111")
    print(f"   - å±€åŸŸç½‘è®¿é—®: http://[ä½ çš„å†…ç½‘IP]:5111") 
    print(f"   - å¤–ç½‘è®¿é—®: http://[ä½ çš„å…¬ç½‘IP]:5111")
    print("="*50)
    print("ğŸ“ å¯ç”¨ç«¯ç‚¹:")
    print(f"   - å¥åº·æ£€æŸ¥: /health")
    print(f"   - å·®å¼‚åˆ†æ: /analyze_diff") 
    print(f"   - æ–‡ä»¶å†å²: /analyze_file_history")
    print(f"   - ç‰ˆæœ¬æ¯”è¾ƒ: /analyze_file_version_comparison")
    print(f"   - æ‰¹é‡åˆ†æ: /analyze_batch")
    print("="*50)
    print("âš ï¸  å®‰å…¨æç¤º:")
    print("   - å½“å‰é…ç½®å…è®¸æ‰€æœ‰IPè®¿é—®")
    print("   - ç”Ÿäº§ç¯å¢ƒè¯·é…ç½®é˜²ç«å¢™è§„åˆ™")
    print("   - å»ºè®®è®¾ç½®APIè®¿é—®é™åˆ¶")
    print("="*50)
    
    # è·å–å¹¶æ˜¾ç¤ºæœ¬æœºIPåœ°å€
    try:
        import socket
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        print(f"ğŸŒ æœ¬æœºIPåœ°å€: {local_ip}")
        print(f"   å±€åŸŸç½‘è®¿é—®é“¾æ¥: http://{local_ip}:5111/health")
    except:
        print("ğŸŒ æ— æ³•è·å–æœ¬æœºIPï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹")
    
    print("="*50)
    print("ğŸš€ æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    
    # Note: Use '0.0.0.0' to be accessible from the extension container
    # Use a specific port, e.g., 5111
    app.run(host='0.0.0.0', port=5111, debug=True)  # ç”Ÿäº§ç¯å¢ƒå»ºè®®debug=False 