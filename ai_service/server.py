# ai_service/server.py

import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import OpenAI, OpenAIError
import prompt_config as prompts

app = Flask(__name__)

# é…ç½®CORSä»¥å…è®¸è·¨åŸŸè®¿é—®
# CORS(app, origins=['*'])  # ç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸå

# --- OpenAI Client Initialization ---
openai_client = None
api_key = os.environ.get("OPENAI_API_KEY")

if api_key:
    try:
        openai_client = OpenAI(api_key=api_key)
        print("OpenAI client initialized successfully.")
    except Exception as e:
        print(f"Error initializing OpenAI client: {e}")
else:
    print("Warning: OPENAI_API_KEY environment variable not set. AI analysis will be disabled.")
# ------------------------------------

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    if openai_client:
        return jsonify({"status": "healthy", "ai_service": "available"}), 200
    else:
        return jsonify({"status": "degraded", "ai_service": "unavailable"}), 200

@app.route('/analyze_diff', methods=['POST'])
def analyze_diff():
    """Analyzes the diff data using OpenAI API if available."""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AI analysis disabled: OPENAI_API_KEY not configured.",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»¼åˆåˆ†æè¯·æ±‚
        if 'file_path' in data and data['file_path'] in ['comprehensive_commit_analysis', 'comprehensive_comparison_analysis', 'comprehensive_uncommitted_analysis']:
            return handle_comprehensive_analysis(data)
        
        # åŸæœ‰çš„å•æ–‡ä»¶åˆ†æé€»è¾‘
        if 'file_diff' not in data or 'file_path' not in data:
            return jsonify({"error": "Missing or invalid data in request (requires file_path and file_diff)"}), 400
        
        file_path = data['file_path']
        file_diff = data['file_diff']
        
        # æ£€æŸ¥diffå†…å®¹æ˜¯å¦ä¸ºç©º
        if not file_diff or file_diff.strip() == '':
            return jsonify({
                "analysis": {
                    "summary": "æ–‡ä»¶æ— å®è´¨æ€§å˜æ›´ã€‚"
                }
            })

        print(f"Received request to analyze diff for: {file_path}")
        file_path = file_path.strip()
        
        # è·å–æ–‡ä»¶ç±»å‹å’Œæ‰©å±•å
        file_extension = file_path.split('.')[-1].lower() if '.' in file_path else ''
        file_name = file_path.split('/')[-1]
        
        # --- OpenAI API Call --- 
        try:
            # æ”¹è¿›çš„æç¤ºè¯ï¼Œæ›´åŠ å…·ä½“å’Œæœ‰é’ˆå¯¹æ€§
            prompt = prompts.build_analyze_diff_prompt(file_path, file_extension, file_name, file_diff)

            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=100,  # å¢åŠ tokené™åˆ¶ä»¥è·å¾—æ›´è¯¦ç»†çš„åˆ†æ
                temperature=0.3,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"OpenAI Summary for {file_path}: {ai_summary}")

        except OpenAIError as e:
            print(f"OpenAI API error for {file_path}: {e}")
            ai_summary = f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}"
        except Exception as e:
            print(f"Unexpected error during OpenAI call for {file_path}: {e}")
            ai_summary = "AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        # -----------------------

        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })

    except json.JSONDecodeError:
        return jsonify({"error": "Invalid JSON format"}), 400
    except Exception as e:
        print(f"Error processing request: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def handle_comprehensive_analysis(data):
    """å¤„ç†é€šç”¨çš„ç»¼åˆæ€§åˆ†æè¯·æ±‚"""
    try:
        file_path_marker = data.get('file_path')
        payload_str = data.get('file_diff', '{}')
        payload = json.loads(payload_str)

        prompt_builders = {
            'comprehensive_commit_analysis': prompts.build_comprehensive_commit_analysis_prompt,
            'comprehensive_uncommitted_analysis': prompts.build_comprehensive_uncommitted_analysis_prompt,
            'comprehensive_comparison_analysis': prompts.build_comprehensive_comparison_prompt
        }

        builder = prompt_builders.get(file_path_marker)
        
        if not builder:
            return jsonify({"error": f"Invalid comprehensive analysis type: {file_path_marker}"}), 400
            
        prompt = builder(payload)
        
        # ä½¿ç”¨OpenAI APIè¿›è¡Œåˆ†æ
        chat_completion = openai_client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Gitä»£ç åˆ†æåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚ï¼Œæä¾›ç²¾å‡†ã€ä¸“ä¸šçš„ä»£ç å˜æ›´åˆ†æã€‚å¦‚æœè¦æ±‚HTMLæ ¼å¼ï¼Œè¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„HTMLç‰‡æ®µã€‚"
                },
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
            model="gpt-4.1-mini",
            max_tokens=800,  # å¢åŠ tokenä»¥é€‚åº”æ›´å¤æ‚çš„åˆ†æ
            temperature=0.3,
            n=1
        )
        ai_summary = chat_completion.choices[0].message.content.strip()
        
        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })
    except (json.JSONDecodeError, KeyError) as e:
        print(f"Error parsing comprehensive analysis payload: {e}")
        return jsonify({"error": "Invalid payload for comprehensive analysis"}), 400
    except OpenAIError as e:
        print(f"OpenAI API error during comprehensive analysis: {e}")
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææ—¶é‡åˆ°APIé”™è¯¯ã€‚",
            }
        })
    except Exception as e:
        print(f"Unexpected error during comprehensive analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def generate_fallback_analysis(error_message="åˆ†ææ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚"):
    """ç”Ÿæˆé™çº§åˆ†æå“åº”"""
    return json.dumps({
        "summary": error_message,
        "evolutionPattern": "æ–‡ä»¶æ¼”è¿›æ¨¡å¼åˆ†æåŸºäºæäº¤å†å²ï¼Œæ˜¾ç¤ºå¼€å‘æ´»è·ƒåº¦å’Œå˜æ›´é¢‘ç‡ã€‚",
        "keyChanges": [
            "ä»£ç ç»“æ„è°ƒæ•´",
            "åŠŸèƒ½å®ç°ä¼˜åŒ–",
            "æ€§èƒ½æ”¹è¿›æªæ–½"
        ],
        "recommendations": [
            "æŒç»­å…³æ³¨ä»£ç è´¨é‡",
            "å®šæœŸè¿›è¡Œé‡æ„ä¼˜åŒ–",
            "åŠ å¼ºæ–‡æ¡£ç»´æŠ¤"
        ]
    }, ensure_ascii=False)

@app.route('/analyze_file_history', methods=['POST'])
def analyze_file_history():
    """ä¸“é—¨å¤„ç†æ–‡ä»¶å†å²åˆ†æçš„ç«¯ç‚¹"""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OpenAI APIé…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ¥æ”¶åŸå§‹æ•°æ®è´Ÿè½½ï¼Œè€Œä¸æ˜¯é¢„æ„å»ºçš„æç¤º
        payload_str = data.get('file_diff', '{}') 
        payload = json.loads(payload_str)
        file_path = payload.get('filePath', 'æœªçŸ¥æ–‡ä»¶')

        if not payload.get('commits'):
            return jsonify({"error": "Missing commits data for file history analysis"}), 400
        
        print(f"Received file history analysis request for: {file_path}")
        
        # åœ¨åç«¯æ„å»ºæç¤º
        base_prompt = prompts.build_file_history_analysis_prompt(payload)
        
        # ä¼˜åŒ–åçš„æ–‡ä»¶å†å²åˆ†ææç¤ºè¯
        enhanced_prompt = prompts.build_enhanced_file_history_prompt(base_prompt)

        try:
            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç æ¼”è¿›åˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬æˆ–æ ¼å¼åŒ–ã€‚"
                    },
                    {
                        "role": "user",
                        "content": enhanced_prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=400,
                temperature=0.2,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"File History Analysis Raw Response for {file_path}: {ai_summary}")

            # å°è¯•éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSON
            try:
                test_parse = json.loads(ai_summary)
                if not all(key in test_parse for key in ['summary', 'evolutionPattern', 'keyChanges', 'recommendations']):
                    raise ValueError("Missing required fields in AI response")
                print(f"File History Analysis JSON validation passed for {file_path}")
            except (json.JSONDecodeError, ValueError) as parse_error:
                print(f"AI returned invalid JSON for {file_path}, using fallback: {parse_error}")
                ai_summary = generate_fallback_analysis(f"AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

            return jsonify({
                "analysis": {
                    "summary": ai_summary,
                }
            })

        except OpenAIError as e:
            print(f"OpenAI API error for file history analysis: {e}")
            fallback_analysis = generate_fallback_analysis(f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })
        except Exception as e:
            print(f"Unexpected error during file history analysis: {e}")
            fallback_analysis = generate_fallback_analysis("AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })

    except Exception as e:
        print(f"Error processing file history analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

@app.route('/analyze_file_version_comparison', methods=['POST'])
def analyze_file_version_comparison():
    """ä¸“é—¨å¤„ç†æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æçš„ç«¯ç‚¹"""
    if not openai_client:
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OpenAI APIé…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ¥æ”¶åŸå§‹æ•°æ®è´Ÿè½½ï¼Œè€Œä¸æ˜¯é¢„æ„å»ºçš„æç¤º
        payload_str = data.get('file_diff', '{}')
        payload = json.loads(payload_str)
        file_path = payload.get('filePath', 'æœªçŸ¥æ–‡ä»¶')
        
        if not payload.get('diffContent'):
            return jsonify({"error": "Missing diffContent for file version comparison"}), 400
        
        print(f"Received file version comparison analysis request for: {file_path}")
        
        # åœ¨åç«¯æ„å»ºæç¤º
        prompt = prompts.build_file_version_comparison_prompt(payload)
        
        try:
            chat_completion = openai_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç ç‰ˆæœ¬æ¯”è¾ƒåˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬æˆ–æ ¼å¼åŒ–ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                model="gpt-4.1-mini",
                max_tokens=500,
                temperature=0.3,
                n=1
            )

            ai_summary = chat_completion.choices[0].message.content.strip()
            print(f"File Version Comparison Analysis Raw Response for {file_path}: {ai_summary}")

            # å°è¯•éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSON
            try:
                test_parse = json.loads(ai_summary)
                required_fields = ['summary', 'changeType', 'impactAnalysis', 'keyModifications', 'recommendations']
                if not all(key in test_parse for key in required_fields):
                    raise ValueError("Missing required fields in AI response")
                print(f"File Version Comparison Analysis JSON validation passed for {file_path}")
            except (json.JSONDecodeError, ValueError) as parse_error:
                print(f"AI returned invalid JSON for {file_path}, using fallback: {parse_error}")
                ai_summary = generate_fallback_analysis(f"AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")

            return jsonify({
                "analysis": {
                    "summary": ai_summary,
                }
            })

        except OpenAIError as e:
            print(f"OpenAI API error for file version comparison analysis: {e}")
            fallback_analysis = generate_fallback_analysis(f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })
        except Exception as e:
            print(f"Unexpected error during file version comparison analysis: {e}")
            fallback_analysis = generate_fallback_analysis("AIåˆ†æé‡åˆ°æœªçŸ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            return jsonify({
                "analysis": {
                    "summary": fallback_analysis,
                }
            })

    except Exception as e:
        print(f"Error processing file version comparison analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

@app.route('/analyze_batch', methods=['POST'])
def analyze_batch():
    """æ‰¹é‡åˆ†æå¤šä¸ªæ–‡ä»¶çš„å·®å¼‚"""
    if not openai_client:
        return jsonify({
            "error": "AI analysis disabled: OPENAI_API_KEY not configured."
        }), 503

    try:
        data = request.get_json()
        if not data or 'files' not in data:
            return jsonify({"error": "Missing files array in request"}), 400
        
        files = data['files']
        if not isinstance(files, list) or len(files) == 0:
            return jsonify({"error": "Files must be a non-empty array"}), 400
        
        # é™åˆ¶æ‰¹é‡å¤„ç†çš„æ–‡ä»¶æ•°é‡
        if len(files) > 10:
            return jsonify({"error": "Too many files in batch (max 10)"}), 400
        
        results = []
        for file_data in files:
            if 'file_path' not in file_data or 'file_diff' not in file_data:
                results.append({
                    "file_path": file_data.get('file_path', 'unknown'),
                    "analysis": None,
                    "error": "Missing file_path or file_diff"
                })
                continue
            
            # é‡ç”¨å•æ–‡ä»¶åˆ†æé€»è¾‘
            try:
                # è¿™é‡Œå¯ä»¥è°ƒç”¨analyze_diffçš„æ ¸å¿ƒé€»è¾‘
                # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›ä¸€ä¸ªç®€å•çš„åˆ†æ
                file_path = file_data['file_path']
                file_name = file_path.split('/')[-1]
                
                results.append({
                    "file_path": file_path,
                    "analysis": {
                        "summary": f"{file_name}: æ–‡ä»¶å·²ä¿®æ”¹ï¼ŒåŒ…å«ä»£ç å˜æ›´ã€‚"
                    },
                    "error": None
                })
            except Exception as e:
                results.append({
                    "file_path": file_data['file_path'],
                    "analysis": None,
                    "error": str(e)
                })
        
        return jsonify({"results": results})
        
    except Exception as e:
        print(f"Error processing batch request: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

if __name__ == '__main__':
    print("Starting AI Analysis Server...")
    print("="*50)
    print("ğŸ”§ æœåŠ¡å™¨é…ç½®:")
    print(f"   - æœ¬åœ°è®¿é—®: http://127.0.0.1:5111")
    print(f"   - å±€åŸŸç½‘è®¿é—®: http://[ä½ çš„å†…ç½‘IP]:5111") 
    print(f"   - å¤–ç½‘è®¿é—®: http://[ä½ çš„å…¬ç½‘IP]:5111")
    print("="*50)
    print("ğŸ“ å¯ç”¨ç«¯ç‚¹:")
    print(f"   - å¥åº·æ£€æŸ¥: /health")
    print(f"   - å·®å¼‚åˆ†æ: /analyze_diff") 
    print(f"   - æ–‡ä»¶å†å²: /analyze_file_history")
    print(f"   - ç‰ˆæœ¬æ¯”è¾ƒ: /analyze_file_version_comparison")
    print(f"   - æ‰¹é‡åˆ†æ: /analyze_batch")
    print("="*50)
    print("âš ï¸  å®‰å…¨æç¤º:")
    print("   - å½“å‰é…ç½®å…è®¸æ‰€æœ‰IPè®¿é—®")
    print("   - ç”Ÿäº§ç¯å¢ƒè¯·é…ç½®é˜²ç«å¢™è§„åˆ™")
    print("   - å»ºè®®è®¾ç½®APIè®¿é—®é™åˆ¶")
    print("="*50)
    
    # è·å–å¹¶æ˜¾ç¤ºæœ¬æœºIPåœ°å€
    try:
        import socket
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        print(f"ğŸŒ æœ¬æœºIPåœ°å€: {local_ip}")
        print(f"   å±€åŸŸç½‘è®¿é—®é“¾æ¥: http://{local_ip}:5111/health")
    except:
        print("ğŸŒ æ— æ³•è·å–æœ¬æœºIPï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹")
    
    print("="*50)
    print("ğŸš€ æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    
    # Note: Use '0.0.0.0' to be accessible from the extension container
    # Use a specific port, e.g., 5111
    app.run(host='0.0.0.0', port=5111, debug=True)  # ç”Ÿäº§ç¯å¢ƒå»ºè®®debug=False 