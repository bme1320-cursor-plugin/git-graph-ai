# ai_service/server.py

import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
import prompt_config as prompts
from model_providers import ModelManager

app = Flask(__name__)
CORS(app)

# --- åˆå§‹åŒ–AIæ¨¡å‹ç®¡ç†å™¨ ---
# ä»ç¯å¢ƒå˜é‡è¯»å–é¦–é€‰çš„AIæä¾›å•†ï¼Œé»˜è®¤ä½¿ç”¨deepseek-v3
preferred_ai_provider = os.environ.get("PREFERRED_AI_PROVIDER", "deepseek-v3")
model_manager = ModelManager(preferred_provider=preferred_ai_provider)
print(f"ğŸš€ AI Service started with preferred provider: {preferred_ai_provider}")
# ------------------------------------

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    if model_manager.is_available():
        provider_info = model_manager.get_current_provider().get_provider_name()
        return jsonify({
            "status": "healthy", 
            "ai_service": "available",
            "current_provider": provider_info
        }), 200
    else:
        return jsonify({
            "status": "degraded", 
            "ai_service": "unavailable",
            "current_provider": None
        }), 200

@app.route('/providers', methods=['GET'])
def get_providers():
    """è·å–æ‰€æœ‰AIæä¾›å•†çš„çŠ¶æ€ä¿¡æ¯"""
    try:
        status = model_manager.get_provider_status()
        return jsonify(status), 200
    except Exception as e:
        return jsonify({"error": f"Failed to get provider status: {str(e)}"}), 500

@app.route('/providers/switch', methods=['POST'])
def switch_provider():
    """åˆ‡æ¢AIæä¾›å•†"""
    try:
        data = request.get_json()
        if not data or 'provider' not in data:
            return jsonify({"error": "Missing 'provider' in request"}), 400
        
        provider_name = data['provider']
        new_provider = model_manager.switch_provider(provider_name)
        
        return jsonify({
            "message": f"Successfully switched to {new_provider}",
            "current_provider": new_provider
        }), 200
        
    except ValueError as e:
        return jsonify({"error": str(e)}), 400
    except Exception as e:
        return jsonify({"error": f"Failed to switch provider: {str(e)}"}), 500

@app.route('/analyze_diff', methods=['POST'])
def analyze_diff():
    """Analyzes the diff data using available AI provider."""
    if not model_manager.is_available():
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥AIæœåŠ¡é…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»¼åˆåˆ†æè¯·æ±‚
        if 'analysis_context' in data and data['analysis_context'] in ['comprehensive_commit_analysis', 'comprehensive_comparison_analysis', 'comprehensive_uncommitted_analysis']:
            return handle_comprehensive_analysis(data)
        
        # åŸæœ‰çš„å•æ–‡ä»¶åˆ†æé€»è¾‘
        if 'file_diff' not in data or 'analysis_context' not in data:
            return jsonify({"error": "Missing or invalid data in request (requires analysis_context and file_diff)"}), 400
        
        analysis_context = data['analysis_context']
        file_diff = data['file_diff']
        
        # æ£€æŸ¥diffå†…å®¹æ˜¯å¦ä¸ºç©º
        if not file_diff or file_diff.strip() == '':
            return jsonify({
                "analysis": {
                    "summary": "æ–‡ä»¶æ— å®è´¨æ€§å˜æ›´ã€‚"
                }
            })

        print(f"Received request to analyze diff for: {analysis_context}")
        analysis_context = analysis_context.strip()
        
        # è·å–æ–‡ä»¶ç±»å‹å’Œæ‰©å±•åï¼ˆå¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„çš„è¯ï¼‰
        file_extension = analysis_context.split('.')[-1].lower() if '.' in analysis_context else ''
        context_name = analysis_context.split('/')[-1]
        
        # --- AI API Call --- 
        try:
            # æ”¹è¿›çš„æç¤ºè¯ï¼Œæ›´åŠ å…·ä½“å’Œæœ‰é’ˆå¯¹æ€§
            prompt = prompts.build_analyze_diff_prompt(analysis_context, file_extension, context_name, file_diff)

            # ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨è°ƒç”¨AI API
            ai_summary = model_manager.chat_completion(
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                max_tokens=100,
                temperature=0.3
            )

            print(f"AI Summary for {analysis_context}: {ai_summary}")

        except Exception as e:
            print(f"AI API error for {analysis_context}: {e}")
            ai_summary = f"AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)}"
        # -----------------------

        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })

    except json.JSONDecodeError:
        return jsonify({"error": "Invalid JSON format"}), 400
    except Exception as e:
        print(f"Error processing request: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

def handle_comprehensive_analysis(data):
    """å¤„ç†é€šç”¨çš„ç»¼åˆæ€§åˆ†æè¯·æ±‚"""
    try:
        analysis_context_marker = data.get('analysis_context')
        payload_str = data.get('file_diff', '{}')
        payload = json.loads(payload_str)

        # ğŸš€ æ–°å¢ï¼šè·å–å½“å‰æ¨¡å‹åç§°ä»¥ä¾¿ä¼˜åŒ– prompt
        current_model_name = 'deepseek-v3'  # é»˜è®¤å€¼
        if model_manager.current_provider:
            provider_name = model_manager.current_provider.get_provider_name()
            if 'OpenAI' in provider_name and 'gpt-4.1' in provider_name.lower():
                current_model_name = 'gpt-4.1-mini' if 'mini' in provider_name.lower() else 'gpt-4.1'
            elif 'Deepseek' in provider_name:
                if 'deepseek-r1' in provider_name.lower():
                    current_model_name = 'deepseek-r1'
                else:
                    current_model_name = 'deepseek-v3'

        prompt_builders = {
            'comprehensive_commit_analysis': lambda payload: prompts.build_comprehensive_commit_analysis_prompt(payload, current_model_name),
            'comprehensive_uncommitted_analysis': lambda payload: prompts.build_comprehensive_uncommitted_analysis_prompt(payload, current_model_name),
            'comprehensive_comparison_analysis': lambda payload: prompts.build_comprehensive_comparison_prompt(payload, current_model_name)
        }

        builder = prompt_builders.get(analysis_context_marker)
        
        if not builder:
            return jsonify({"error": f"Invalid comprehensive analysis type: {analysis_context_marker}"}), 400
            
        prompt = builder(payload)
        
        print(f"ğŸ”§ Using model-optimized prompt for {current_model_name}, context: {analysis_context_marker}")
        
        # ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨è¿›è¡Œåˆ†æ
        ai_summary = model_manager.chat_completion(
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Gitä»£ç åˆ†æåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚ï¼Œæä¾›ç²¾å‡†ã€ä¸“ä¸šçš„ä»£ç å˜æ›´åˆ†æã€‚å¦‚æœè¦æ±‚HTMLæ ¼å¼ï¼Œè¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„HTMLç‰‡æ®µã€‚"
                },
                {
                    "role": "user",
                    "content": prompt,
                }
            ],
            max_tokens=800,
            temperature=0.3
        )
        
        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })
    except (json.JSONDecodeError, KeyError) as e:
        print(f"Error parsing comprehensive analysis payload: {e}")
        return jsonify({"error": "Invalid payload for comprehensive analysis"}), 400
    except Exception as e:
        print(f"AI API error during comprehensive analysis: {e}")
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææ—¶é‡åˆ°APIé”™è¯¯ã€‚",
            }
        })

def generate_fallback_analysis(error_message="åˆ†ææ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚"):
    """ç”Ÿæˆé™çº§åˆ†æå“åº”"""
    return json.dumps({
        "summary": error_message,
        "evolutionPattern": "æ–‡ä»¶æ¼”è¿›æ¨¡å¼åˆ†æåŸºäºæäº¤å†å²ï¼Œæ˜¾ç¤ºå¼€å‘æ´»è·ƒåº¦å’Œå˜æ›´é¢‘ç‡ã€‚",
        "keyChanges": [
            "ä»£ç ç»“æ„è°ƒæ•´",
            "åŠŸèƒ½å®ç°ä¼˜åŒ–",
            "æ€§èƒ½æ”¹è¿›æªæ–½"
        ],
        "recommendations": [
            "æŒç»­å…³æ³¨ä»£ç è´¨é‡",
            "å®šæœŸè¿›è¡Œé‡æ„ä¼˜åŒ–",
            "åŠ å¼ºæ–‡æ¡£ç»´æŠ¤"
        ]
    }, ensure_ascii=False)

@app.route('/analyze_file_history', methods=['POST'])
def analyze_file_history():
    """ä¸“é—¨å¤„ç†æ–‡ä»¶å†å²åˆ†æçš„ç«¯ç‚¹"""
    if not model_manager.is_available():
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥AIæœåŠ¡é…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ¥æ”¶åŸå§‹æ•°æ®è´Ÿè½½ï¼Œè€Œä¸æ˜¯é¢„æ„å»ºçš„æç¤º
        payload_str = data.get('file_diff', '{}') 
        payload = json.loads(payload_str)
        analysis_context = data.get('analysis_context', 'æœªçŸ¥æ–‡ä»¶')

        if not payload.get('commits'):
            return jsonify({"error": "Missing commits data for file history analysis"}), 400
        
        print(f"Received file history analysis request for: {analysis_context}")
        
        # åœ¨åç«¯æ„å»ºæç¤º
        base_prompt = prompts.build_file_history_analysis_prompt(payload)
        
        # ä¼˜åŒ–åçš„æ–‡ä»¶å†å²åˆ†ææç¤ºè¯
        enhanced_prompt = prompts.build_enhanced_file_history_prompt(base_prompt)

        try:
            ai_summary = model_manager.chat_completion(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç æ¼”è¿›åˆ†æå¸ˆã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼å›ç­”ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„æ–‡æœ¬æˆ–æ ¼å¼åŒ–ã€‚"
                    },
                    {
                        "role": "user",
                        "content": enhanced_prompt,
                    }
                ],
                max_tokens=400,
                temperature=0.2
            )

            print(f"File History Analysis Raw Response for {analysis_context}: {ai_summary}")

            # å°è¯•éªŒè¯è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSON
            try:
                test_parse = json.loads(ai_summary)
                if not all(key in test_parse for key in ['summary', 'evolutionPattern', 'keyChanges', 'recommendations']):
                    raise ValueError("Missing required fields in AI response")
            except (json.JSONDecodeError, ValueError):
                print(f"Invalid JSON response for {analysis_context}, using fallback")
                ai_summary = generate_fallback_analysis("AIè¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œå·²ä½¿ç”¨é»˜è®¤åˆ†æã€‚")

        except Exception as e:
            print(f"AI API error for file history analysis {analysis_context}: {e}")
            ai_summary = generate_fallback_analysis(f"AIåˆ†ææ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")

        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })

    except (json.JSONDecodeError, KeyError) as e:
        print(f"Error parsing file history analysis payload: {e}")
        return jsonify({"error": "Invalid payload for file history analysis"}), 400
    except Exception as e:
        print(f"Unexpected error during file history analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

@app.route('/analyze_file_version_comparison', methods=['POST'])
def analyze_file_version_comparison():
    """å¤„ç†æ–‡ä»¶ç‰ˆæœ¬æ¯”è¾ƒåˆ†æçš„ç«¯ç‚¹"""
    if not model_manager.is_available():
        return jsonify({
            "analysis": {
                "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥AIæœåŠ¡é…ç½®ã€‚",
            }
        })

    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "Missing data in request"}), 400
        
        # æ¥æ”¶åŸå§‹æ•°æ®è´Ÿè½½
        payload_str = data.get('file_diff', '{}') 
        payload = json.loads(payload_str)
        analysis_context = data.get('analysis_context', 'æœªçŸ¥æ–‡ä»¶')

        if not payload.get('contentBefore') and not payload.get('contentAfter'):
            return jsonify({"error": "Missing file content data for version comparison"}), 400
        
        print(f"Received file version comparison request for: {analysis_context}")
        
        # æ„å»ºç‰ˆæœ¬æ¯”è¾ƒåˆ†ææç¤º
        prompt = prompts.build_file_version_comparison_prompt(payload)

        try:
            ai_summary = model_manager.chat_completion(
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç ç‰ˆæœ¬æ¯”è¾ƒåˆ†æå¸ˆã€‚è¯·æä¾›ç²¾å‡†ã€ä¸“ä¸šçš„ç‰ˆæœ¬å·®å¼‚åˆ†æã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                max_tokens=300,
                temperature=0.3
            )

            print(f"File Version Comparison Analysis for {analysis_context}: {ai_summary}")

        except Exception as e:
            print(f"AI API error for file version comparison {analysis_context}: {e}")
            ai_summary = f"AIåˆ†ææ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

        return jsonify({
            "analysis": {
                "summary": ai_summary,
            }
        })

    except (json.JSONDecodeError, KeyError) as e:
        print(f"Error parsing file version comparison payload: {e}")
        return jsonify({"error": "Invalid payload for file version comparison"}), 400
    except Exception as e:
        print(f"Unexpected error during file version comparison: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

@app.route('/analyze_batch', methods=['POST'])
def analyze_batch():
    """æ‰¹é‡åˆ†æå¤šä¸ªæ–‡ä»¶çš„å·®å¼‚"""
    if not model_manager.is_available():
        return jsonify({
            "analyses": [],
            "summary": "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥AIæœåŠ¡é…ç½®ã€‚"
        })

    try:
        data = request.get_json()
        if not data or 'files' not in data:
            return jsonify({"error": "Missing 'files' in request"}), 400
        
        files = data['files']
        if not isinstance(files, list):
            return jsonify({"error": "'files' must be an array"}), 400
        
        analyses = []
        
        for file_data in files:
            if 'analysis_context' not in file_data or 'file_diff' not in file_data:
                continue
            
            analysis_context = file_data['analysis_context']
            file_diff = file_data['file_diff']
            
            # è·³è¿‡ç©ºçš„diff
            if not file_diff or file_diff.strip() == '':
                analyses.append({
                    "analysis_context": analysis_context,
                    "analysis": {
                        "summary": "æ–‡ä»¶æ— å®è´¨æ€§å˜æ›´ã€‚"
                    }
                })
                continue
            
            try:
                # è·å–æ–‡ä»¶ç±»å‹å’Œæ‰©å±•å
                file_extension = analysis_context.split('.')[-1].lower() if '.' in analysis_context else ''
                context_name = analysis_context.split('/')[-1]
                
                # æ„å»ºæç¤ºè¯
                prompt = prompts.build_analyze_diff_prompt(analysis_context, file_extension, context_name, file_diff)
                
                # AIåˆ†æ
                ai_summary = model_manager.chat_completion(
                    messages=[
                        {
                            "role": "user",
                            "content": prompt,
                        }
                    ],
                    max_tokens=100,
                    temperature=0.3
                )
                
                analyses.append({
                    "analysis_context": analysis_context,
                    "analysis": {
                        "summary": ai_summary,
                    }
                })
                
            except Exception as e:
                print(f"Error analyzing {analysis_context}: {e}")
                analyses.append({
                    "analysis_context": analysis_context,
                    "analysis": {
                        "summary": f"åˆ†æå¤±è´¥ï¼š{str(e)}"
                    }
                })
        
        return jsonify({
            "analyses": analyses,
            "total_files": len(files),
            "analyzed_files": len(analyses)
        })

    except Exception as e:
        print(f"Error in batch analysis: {e}")
        return jsonify({"error": "An internal server error occurred"}), 500

if __name__ == '__main__':
    print("ğŸ¯ Starting AI Analysis Service...")
    print(f"ğŸ¤– Using AI Provider: {model_manager.get_current_provider().get_provider_name() if model_manager.is_available() else 'None'}")
    app.run(host='0.0.0.0', port=5111, debug=True) 